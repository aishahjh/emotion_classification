{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132a7776",
   "metadata": {},
   "source": [
    "# Emotion classification on GoEmotions - Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aea7b3",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "import transformers\n",
    "from transformers import  AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback, EarlyStoppingCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced187be",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d73c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  admiration  amusement  \\\n",
       "0  my favourite food is anything i did not have t...           0          0   \n",
       "1  now if he does off himself everyone will think...           0          0   \n",
       "2                     why the fuck is bayless isoing           0          0   \n",
       "3                        to make her feel threatened           0          0   \n",
       "4                             dirty southern wankers           0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
       "0      0          0         0       0          0          0       0  ...   \n",
       "1      0          0         0       0          0          0       0  ...   \n",
       "2      1          0         0       0          0          0       0  ...   \n",
       "3      0          0         0       0          0          0       0  ...   \n",
       "4      0          1         0       0          0          0       0  ...   \n",
       "\n",
       "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0     0            0         0      0            0       0        0        0   \n",
       "1     0            0         0      0            0       0        0        0   \n",
       "2     0            0         0      0            0       0        0        0   \n",
       "3     0            0         0      0            0       0        0        0   \n",
       "4     0            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean the generated augmented data\n",
    "def clean_text(text):\n",
    "    chars_to_remove = [\"’\", \"‘\", \"–\", \"—\", \"~\", \"|\", \"“\", \"”\", \"…\", \"'\", \"`\", \"_\",\"“\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    \n",
    "    #handle emoticons and emojis\n",
    "    text = handle_emoticons (text)\n",
    "    text = handle_emojis (text)\n",
    "\n",
    "    text = text.lower()# lower case\n",
    "    \n",
    "    #fix contraction from text\n",
    "    #Fix contraction before removing punctuation is important \n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    text = re.sub(r\"http\\S*|\\S*\\.com\\S*|\\S*www\\S*\", \" \", text)# eliminate urls\n",
    "    text = re.sub(r\"\\s@\\S+\", \" \", text)# eliminate @mentions\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]',' ', text) #remove all punctuations\n",
    "    text = re.sub(r'\\n', '', text) #remove line breaks\n",
    "    text = re.sub(rx, ' ', text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # replace all whitespaces with a single space\n",
    "    text = text.strip() #remove leading and trailing spaces\n",
    "\n",
    "\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59fb02",
   "metadata": {},
   "source": [
    "## 2. Performing Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53618c4e",
   "metadata": {},
   "source": [
    "### Bert based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfa07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BERT-based augmenter\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased',\n",
    "    action=\"insert\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e778d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to the 'clean_text' column\n",
    "bert_train_df['augmented_text'] = bert_train_df['clean_text'].apply(lambda x: aug.augment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02197a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>augmented_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['my favourite food is anything the i did requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['and now surely if tonight he does strip off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['but why the damn fuck is this bayless isoing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['to forcibly make her parents feel threatened']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['as dirty southern bill wankers']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['it added you to mate well i may have also ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['always i thought it that which was funny or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['what are you talking talking about anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['feel more... like a sex baptism with sexy re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['enjoy the thrill ride']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43408 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       admiration  amusement  anger  annoyance  approval  caring  confusion  \\\n",
       "0               0          0      0          0         0       0          0   \n",
       "1               0          0      0          0         0       0          0   \n",
       "2               0          0      1          0         0       0          0   \n",
       "3               0          0      0          0         0       0          0   \n",
       "4               0          0      0          1         0       0          0   \n",
       "...           ...        ...    ...        ...       ...     ...        ...   \n",
       "43403           0          0      0          0         0       0          0   \n",
       "43404           0          0      0          0         0       0          1   \n",
       "43405           0          0      0          1         0       0          0   \n",
       "43406           0          0      0          0         0       0          0   \n",
       "43407           0          0      0          0         0       0          0   \n",
       "\n",
       "       curiosity  desire  disappointment  ...  nervousness  optimism  pride  \\\n",
       "0              0       0               0  ...            0         0      0   \n",
       "1              0       0               0  ...            0         0      0   \n",
       "2              0       0               0  ...            0         0      0   \n",
       "3              0       0               0  ...            0         0      0   \n",
       "4              0       0               0  ...            0         0      0   \n",
       "...          ...     ...             ...  ...          ...       ...    ...   \n",
       "43403          0       0               0  ...            0         0      0   \n",
       "43404          0       0               0  ...            0         0      0   \n",
       "43405          0       0               0  ...            0         0      0   \n",
       "43406          0       0               0  ...            0         0      0   \n",
       "43407          0       0               0  ...            0         0      0   \n",
       "\n",
       "       realization  relief  remorse  sadness  surprise  neutral  \\\n",
       "0                0       0        0        0         0        1   \n",
       "1                0       0        0        0         0        1   \n",
       "2                0       0        0        0         0        0   \n",
       "3                0       0        0        0         0        0   \n",
       "4                0       0        0        0         0        0   \n",
       "...            ...     ...      ...      ...       ...      ...   \n",
       "43403            0       0        0        0         0        0   \n",
       "43404            0       0        0        0         0        0   \n",
       "43405            0       0        0        0         0        0   \n",
       "43406            0       0        0        0         0        0   \n",
       "43407            0       0        0        0         0        0   \n",
       "\n",
       "                                          augmented_text  \n",
       "0      ['my favourite food is anything the i did requ...  \n",
       "1      ['and now surely if tonight he does strip off ...  \n",
       "2       ['but why the damn fuck is this bayless isoing']  \n",
       "3       ['to forcibly make her parents feel threatened']  \n",
       "4                     ['as dirty southern bill wankers']  \n",
       "...                                                  ...  \n",
       "43403  ['it added you to mate well i may have also ju...  \n",
       "43404  ['always i thought it that which was funny or ...  \n",
       "43405  ['what are you talking talking about anything ...  \n",
       "43406  ['feel more... like a sex baptism with sexy re...  \n",
       "43407                          ['enjoy the thrill ride']  \n",
       "\n",
       "[43408 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train_df.drop(columns=['clean_text'], inplace=True)\n",
    "bert_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb27e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df.rename(columns={'augmented_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42e1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df['text'] = bert_train_df['text'].str.strip(\"['']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df['clean_text'] = bert_train_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74216000",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31d57e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>my favourite food is anything the i did requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and now surely if tonight he does strip off hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>but why the damn fuck is this bayless isoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to forcibly make her parents feel threatened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>as dirty southern bill wankers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admiration  amusement  anger  annoyance  approval  caring  confusion  \\\n",
       "0           0          0      0          0         0       0          0   \n",
       "1           0          0      0          0         0       0          0   \n",
       "2           0          0      1          0         0       0          0   \n",
       "3           0          0      0          0         0       0          0   \n",
       "4           0          0      0          1         0       0          0   \n",
       "\n",
       "   curiosity  desire  disappointment  ...  nervousness  optimism  pride  \\\n",
       "0          0       0               0  ...            0         0      0   \n",
       "1          0       0               0  ...            0         0      0   \n",
       "2          0       0               0  ...            0         0      0   \n",
       "3          0       0               0  ...            0         0      0   \n",
       "4          0       0               0  ...            0         0      0   \n",
       "\n",
       "   realization  relief  remorse  sadness  surprise  neutral  \\\n",
       "0            0       0        0        0         0        1   \n",
       "1            0       0        0        0         0        1   \n",
       "2            0       0        0        0         0        0   \n",
       "3            0       0        0        0         0        0   \n",
       "4            0       0        0        0         0        0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  my favourite food is anything the i did requir...  \n",
       "1  and now surely if tonight he does strip off hi...  \n",
       "2       but why the damn fuck is this bayless isoing  \n",
       "3       to forcibly make her parents feel threatened  \n",
       "4                     as dirty southern bill wankers  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_df.to_csv('data/clean/augmented/augmented_insert_train.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83abe96b",
   "metadata": {},
   "source": [
    "### Word2Vec based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type: word2vec\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path='GoogleNews-vectors-negative300.bin',\n",
    "    action=\"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98124df",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to the 'clean_text' column\n",
    "w2v_train_df['augmented_text'] = w2v_train_df['clean_text'].apply(lambda x: aug.augment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683f29b",
   "metadata": {},
   "source": [
    "Drop necessary columns, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03215ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_df.rename(columns={'augmented_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train contained clean_text column, need to replace it so have to drop it first\n",
    "w2v_train_df.drop(columns=['clean_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the text from brackets\n",
    "w2v_train_df['text'] = w2v_train_df['text'].str.strip(\"['']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the clean text function\n",
    "w2v_train_df['clean_text'] = w2v_train_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the csv\n",
    "w2v_train_df.to_csv('data/clean/augmented/augmented_w2v_train.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e292b",
   "metadata": {},
   "source": [
    "### WordNet based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54811eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93499671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the df_train\n",
    "wordnet_train_df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to the 'clean_text' column\n",
    "wordnet_train_df['augmented_text'] = wordnet_train_df['clean_text'].apply(lambda x: aug.augment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d02c3",
   "metadata": {},
   "source": [
    "Drop necessary columns, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_train_df.rename(columns={'augmented_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc017e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train contained clean_text column, need to replace it so have to drop it first\n",
    "wordnet_train_df.drop(columns=['clean_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the text from brackets\n",
    "wordnet_train_df['text'] = wordnet_train_df['text'].str.strip(\"['']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07521ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the clean text function\n",
    "wordnet_train_df['clean_text'] = wordnet_train_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_train_df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd023988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the csv\n",
    "wordnet_train_df.to_csv('data/clean/augmented/augmented_wordnet_subs_train.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
