{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Roberta M3 (with class weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.d# Roberta M1 (with class weight)\n",
    "\n",
    "Importing the necessary librariesata import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "import copy\n",
    "from typing import Optional\n",
    "from torch import FloatTensor\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d73c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  admiration  amusement  \\\n",
       "0  my favourite food is anything i did not have t...           0          0   \n",
       "1  now if he does off himself everyone will think...           0          0   \n",
       "2                     why the fuck is bayless isoing           0          0   \n",
       "3                        to make her feel threatened           0          0   \n",
       "4                             dirty southern wankers           0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
       "0      0          0         0       0          0          0       0  ...   \n",
       "1      0          0         0       0          0          0       0  ...   \n",
       "2      1          0         0       0          0          0       0  ...   \n",
       "3      0          0         0       0          0          0       0  ...   \n",
       "4      0          1         0       0          0          0       0  ...   \n",
       "\n",
       "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0     0            0         0      0            0       0        0        0   \n",
       "1     0            0         0      0            0       0        0        0   \n",
       "2     0            0         0      0            0       0        0        0   \n",
       "3     0            0         0      0            0       0        0        0   \n",
       "4     0            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46926bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 3e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af580be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43261378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffe4fe",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7c54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3d783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training set\n",
    "train_encodings = tokenizer(list(df_train['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],\n",
    "                                   'attention_mask': train_encodings['attention_mask'],\n",
    "                                   'labels': torch.tensor(df_train[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "# Tokenize the validation set\n",
    "val_encodings = tokenizer(list(df_val['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "valid_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],\n",
    "                                 'attention_mask': val_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_val[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(list(df_test['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],\n",
    "                                 'attention_mask': test_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_test[target_cols].values, dtype=torch.float32)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4840",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0442a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download model from model hub\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(target_cols))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e91901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom callback to get train and validation info during training\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb5596",
   "metadata": {},
   "source": [
    "#### Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdb39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "num_classes = len(target_cols)\n",
    "class_counts = np.sum(train_dataset['labels'], axis=0)\n",
    "class_weights = 1.0 / class_counts\n",
    "\n",
    "# Normalize weights\n",
    "class_weights /= class_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82eeccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00434095, 0.00770108, 0.01144105, 0.00725835, 0.00610007,\n",
       "       0.01649321, 0.01310535, 0.00818262, 0.02796899, 0.0141389 ,\n",
       "       0.00886653, 0.02260797, 0.05936463, 0.02101773, 0.03013129,\n",
       "       0.00673483, 0.23283272, 0.01234719, 0.0085945 , 0.10998846,\n",
       "       0.01133973, 0.16151459, 0.01615146, 0.11717725, 0.03289563,\n",
       "       0.01353066, 0.01691332, 0.00126095])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611e9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom trainer to incorporate class weights\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights: Optional[FloatTensor] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            class_weights = class_weights.to(self.args.device)\n",
    "            logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
    "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        try:\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1,model.num_labels))\n",
    "        except AttributeError:  # DataParallel\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1, model.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e338b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1980801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='data/output/',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_dir=\"data/output/logs\",\n",
    "    learning_rate=float(LEARNING_RATE),\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0eae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to calculate the metrics for multi label classification\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3287773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Trainer instance\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.add_callback(CustomCallback(trainer)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e1c6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishah/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10852' max='10852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10852/10852 1:37:29, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.448443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>0.552714</td>\n",
       "      <td>0.458934</td>\n",
       "      <td>0.694662</td>\n",
       "      <td>0.725046</td>\n",
       "      <td>0.434021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.533984</td>\n",
       "      <td>0.775142</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.502557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.570467</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.734689</td>\n",
       "      <td>0.448397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.612149</td>\n",
       "      <td>0.803901</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.575640</td>\n",
       "      <td>0.498903</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>0.744312</td>\n",
       "      <td>0.458164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.058027</td>\n",
       "      <td>0.732053</td>\n",
       "      <td>0.655205</td>\n",
       "      <td>0.829324</td>\n",
       "      <td>0.824644</td>\n",
       "      <td>0.614633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.667833</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.464615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10852, training_loss=0.085156455674472, metrics={'train_runtime': 5850.7717, 'train_samples_per_second': 29.677, 'train_steps_per_second': 1.855, 'total_flos': 1.8563660177547264e+16, 'train_loss': 0.085156455674472, 'epoch': 4.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dffa6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1671</td>\n",
       "      <td>2.861777e-05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1175</td>\n",
       "      <td>2.723553e-05</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1067</td>\n",
       "      <td>2.585330e-05</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0987</td>\n",
       "      <td>2.447107e-05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0955</td>\n",
       "      <td>2.308883e-05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.448443</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>0.552714</td>\n",
       "      <td>0.458934</td>\n",
       "      <td>0.694662</td>\n",
       "      <td>0.725046</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>21.6364</td>\n",
       "      <td>250.781</td>\n",
       "      <td>15.714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0899</td>\n",
       "      <td>2.170660e-05</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0875</td>\n",
       "      <td>2.032436e-05</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>1.894213e-05</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0835</td>\n",
       "      <td>1.755990e-05</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0843</td>\n",
       "      <td>1.617766e-05</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.533984</td>\n",
       "      <td>0.775142</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.502557</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.570467</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.734689</td>\n",
       "      <td>0.448397</td>\n",
       "      <td>20.6102</td>\n",
       "      <td>263.268</td>\n",
       "      <td>16.497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0809</td>\n",
       "      <td>1.479543e-05</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0760</td>\n",
       "      <td>1.341320e-05</td>\n",
       "      <td>2.21</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0737</td>\n",
       "      <td>1.203096e-05</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0746</td>\n",
       "      <td>1.064873e-05</td>\n",
       "      <td>2.58</td>\n",
       "      <td>7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0730</td>\n",
       "      <td>9.266495e-06</td>\n",
       "      <td>2.76</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0752</td>\n",
       "      <td>7.884261e-06</td>\n",
       "      <td>2.95</td>\n",
       "      <td>8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.612149</td>\n",
       "      <td>0.803901</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.575640</td>\n",
       "      <td>0.498903</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>0.744312</td>\n",
       "      <td>0.458164</td>\n",
       "      <td>21.2735</td>\n",
       "      <td>255.059</td>\n",
       "      <td>15.982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0685</td>\n",
       "      <td>6.502027e-06</td>\n",
       "      <td>3.13</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0657</td>\n",
       "      <td>5.119794e-06</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0659</td>\n",
       "      <td>3.737560e-06</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0653</td>\n",
       "      <td>2.355326e-06</td>\n",
       "      <td>3.69</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0663</td>\n",
       "      <td>9.730925e-07</td>\n",
       "      <td>3.87</td>\n",
       "      <td>10500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.058027</td>\n",
       "      <td>0.732053</td>\n",
       "      <td>0.655205</td>\n",
       "      <td>0.829324</td>\n",
       "      <td>0.824644</td>\n",
       "      <td>0.614633</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.667833</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.464615</td>\n",
       "      <td>21.2916</td>\n",
       "      <td>254.843</td>\n",
       "      <td>15.969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.085156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.856366e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "0   0.1671   2.861777e-05   0.18    500         NaN       NaN           NaN   \n",
       "1   0.1175   2.723553e-05   0.37   1000         NaN       NaN           NaN   \n",
       "2   0.1067   2.585330e-05   0.55   1500         NaN       NaN           NaN   \n",
       "3   0.0987   2.447107e-05   0.74   2000         NaN       NaN           NaN   \n",
       "4   0.0955   2.308883e-05   0.92   2500         NaN       NaN           NaN   \n",
       "5      NaN            NaN   1.00   2713    0.086467  0.572314      0.475273   \n",
       "6      NaN            NaN   1.00   2713         NaN       NaN           NaN   \n",
       "7   0.0899   2.170660e-05   1.11   3000         NaN       NaN           NaN   \n",
       "8   0.0875   2.032436e-05   1.29   3500         NaN       NaN           NaN   \n",
       "9   0.0859   1.894213e-05   1.47   4000         NaN       NaN           NaN   \n",
       "10  0.0835   1.755990e-05   1.66   4500         NaN       NaN           NaN   \n",
       "11  0.0843   1.617766e-05   1.84   5000         NaN       NaN           NaN   \n",
       "12     NaN            NaN   2.00   5426    0.073168  0.632351      0.533984   \n",
       "13     NaN            NaN   2.00   5426         NaN       NaN           NaN   \n",
       "14  0.0809   1.479543e-05   2.03   5500         NaN       NaN           NaN   \n",
       "15  0.0760   1.341320e-05   2.21   6000         NaN       NaN           NaN   \n",
       "16  0.0737   1.203096e-05   2.40   6500         NaN       NaN           NaN   \n",
       "17  0.0746   1.064873e-05   2.58   7000         NaN       NaN           NaN   \n",
       "18  0.0730   9.266495e-06   2.76   7500         NaN       NaN           NaN   \n",
       "19  0.0752   7.884261e-06   2.95   8000         NaN       NaN           NaN   \n",
       "20     NaN            NaN   3.00   8139    0.063692  0.695043      0.612149   \n",
       "21     NaN            NaN   3.00   8139         NaN       NaN           NaN   \n",
       "22  0.0685   6.502027e-06   3.13   8500         NaN       NaN           NaN   \n",
       "23  0.0657   5.119794e-06   3.32   9000         NaN       NaN           NaN   \n",
       "24  0.0659   3.737560e-06   3.50   9500         NaN       NaN           NaN   \n",
       "25  0.0653   2.355326e-06   3.69  10000         NaN       NaN           NaN   \n",
       "26  0.0663   9.730925e-07   3.87  10500         NaN       NaN           NaN   \n",
       "27     NaN            NaN   4.00  10852    0.058027  0.732053      0.655205   \n",
       "28     NaN            NaN   4.00  10852         NaN       NaN           NaN   \n",
       "29     NaN            NaN   4.00  10852    0.085156       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "0               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "1               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "2               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "3               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "4               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "5          0.719151       0.733564        0.448443  ...        NaN       NaN   \n",
       "6               NaN            NaN             NaN  ...   0.090692  0.552714   \n",
       "7               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "8               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "9               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "10              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "11              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "12         0.775142       0.763593        0.502557  ...        NaN       NaN   \n",
       "13              NaN            NaN             NaN  ...   0.084908  0.570467   \n",
       "14              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "15              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "16              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "17              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "18              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "19              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "20         0.803901       0.802798        0.571600  ...        NaN       NaN   \n",
       "21              NaN            NaN             NaN  ...   0.084577  0.575640   \n",
       "22              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "23              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "24              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "25              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "26              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "27         0.829324       0.824644        0.614633  ...        NaN       NaN   \n",
       "28              NaN            NaN             NaN  ...   0.085617  0.577454   \n",
       "29              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "0           NaN             NaN           NaN            NaN           NaN   \n",
       "1           NaN             NaN           NaN            NaN           NaN   \n",
       "2           NaN             NaN           NaN            NaN           NaN   \n",
       "3           NaN             NaN           NaN            NaN           NaN   \n",
       "4           NaN             NaN           NaN            NaN           NaN   \n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "6      0.458934        0.694662      0.725046       0.434021       21.6364   \n",
       "7           NaN             NaN           NaN            NaN           NaN   \n",
       "8           NaN             NaN           NaN            NaN           NaN   \n",
       "9           NaN             NaN           NaN            NaN           NaN   \n",
       "10          NaN             NaN           NaN            NaN           NaN   \n",
       "11          NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "13     0.478056        0.707164      0.734689       0.448397       20.6102   \n",
       "14          NaN             NaN           NaN            NaN           NaN   \n",
       "15          NaN             NaN           NaN            NaN           NaN   \n",
       "16          NaN             NaN           NaN            NaN           NaN   \n",
       "17          NaN             NaN           NaN            NaN           NaN   \n",
       "18          NaN             NaN           NaN            NaN           NaN   \n",
       "19          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "21     0.498903        0.680274      0.744312       0.458164       21.2735   \n",
       "22          NaN             NaN           NaN            NaN           NaN   \n",
       "23          NaN             NaN           NaN            NaN           NaN   \n",
       "24          NaN             NaN           NaN            NaN           NaN   \n",
       "25          NaN             NaN           NaN            NaN           NaN   \n",
       "26          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "28     0.508621        0.667833      0.748766       0.464615       21.2916   \n",
       "29          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second    total_flos  \n",
       "0                       NaN                    NaN           NaN  \n",
       "1                       NaN                    NaN           NaN  \n",
       "2                       NaN                    NaN           NaN  \n",
       "3                       NaN                    NaN           NaN  \n",
       "4                       NaN                    NaN           NaN  \n",
       "5                       NaN                    NaN           NaN  \n",
       "6                   250.781                 15.714           NaN  \n",
       "7                       NaN                    NaN           NaN  \n",
       "8                       NaN                    NaN           NaN  \n",
       "9                       NaN                    NaN           NaN  \n",
       "10                      NaN                    NaN           NaN  \n",
       "11                      NaN                    NaN           NaN  \n",
       "12                      NaN                    NaN           NaN  \n",
       "13                  263.268                 16.497           NaN  \n",
       "14                      NaN                    NaN           NaN  \n",
       "15                      NaN                    NaN           NaN  \n",
       "16                      NaN                    NaN           NaN  \n",
       "17                      NaN                    NaN           NaN  \n",
       "18                      NaN                    NaN           NaN  \n",
       "19                      NaN                    NaN           NaN  \n",
       "20                      NaN                    NaN           NaN  \n",
       "21                  255.059                 15.982           NaN  \n",
       "22                      NaN                    NaN           NaN  \n",
       "23                      NaN                    NaN           NaN  \n",
       "24                      NaN                    NaN           NaN  \n",
       "25                      NaN                    NaN           NaN  \n",
       "26                      NaN                    NaN           NaN  \n",
       "27                      NaN                    NaN           NaN  \n",
       "28                  254.843                 15.969           NaN  \n",
       "29                      NaN                    NaN  1.856366e+16  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view train and validation metrics from training\n",
    "log_history = pd.DataFrame(trainer.state.log_history)\n",
    "log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf0d198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.448443</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.533984</td>\n",
       "      <td>0.775142</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.502557</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.612149</td>\n",
       "      <td>0.803901</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.058027</td>\n",
       "      <td>0.732053</td>\n",
       "      <td>0.655205</td>\n",
       "      <td>0.829324</td>\n",
       "      <td>0.824644</td>\n",
       "      <td>0.614633</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "5    NaN            NaN    1.0   2713    0.086467  0.572314      0.475273   \n",
       "12   NaN            NaN    2.0   5426    0.073168  0.632351      0.533984   \n",
       "20   NaN            NaN    3.0   8139    0.063692  0.695043      0.612149   \n",
       "27   NaN            NaN    4.0  10852    0.058027  0.732053      0.655205   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss  eval_f1  \\\n",
       "5          0.719151       0.733564        0.448443  ...        NaN      NaN   \n",
       "12         0.775142       0.763593        0.502557  ...        NaN      NaN   \n",
       "20         0.803901       0.802798        0.571600  ...        NaN      NaN   \n",
       "27         0.829324       0.824644        0.614633  ...        NaN      NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "5                       NaN                    NaN         NaN  \n",
       "12                      NaN                    NaN         NaN  \n",
       "20                      NaN                    NaN         NaN  \n",
       "27                      NaN                    NaN         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store train metrics in dataframe\n",
    "train_history = log_history[log_history['train_f1'].notna()]\n",
    "train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97eea248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>0.552714</td>\n",
       "      <td>0.458934</td>\n",
       "      <td>0.694662</td>\n",
       "      <td>0.725046</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>21.6364</td>\n",
       "      <td>250.781</td>\n",
       "      <td>15.714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.570467</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.734689</td>\n",
       "      <td>0.448397</td>\n",
       "      <td>20.6102</td>\n",
       "      <td>263.268</td>\n",
       "      <td>16.497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.575640</td>\n",
       "      <td>0.498903</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>0.744312</td>\n",
       "      <td>0.458164</td>\n",
       "      <td>21.2735</td>\n",
       "      <td>255.059</td>\n",
       "      <td>15.982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.667833</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.464615</td>\n",
       "      <td>21.2916</td>\n",
       "      <td>254.843</td>\n",
       "      <td>15.969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "6    NaN            NaN    1.0   2713         NaN       NaN           NaN   \n",
       "13   NaN            NaN    2.0   5426         NaN       NaN           NaN   \n",
       "21   NaN            NaN    3.0   8139         NaN       NaN           NaN   \n",
       "28   NaN            NaN    4.0  10852         NaN       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "6               NaN            NaN             NaN  ...   0.090692  0.552714   \n",
       "13              NaN            NaN             NaN  ...   0.084908  0.570467   \n",
       "21              NaN            NaN             NaN  ...   0.084577  0.575640   \n",
       "28              NaN            NaN             NaN  ...   0.085617  0.577454   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "6      0.458934        0.694662      0.725046       0.434021       21.6364   \n",
       "13     0.478056        0.707164      0.734689       0.448397       20.6102   \n",
       "21     0.498903        0.680274      0.744312       0.458164       21.2735   \n",
       "28     0.508621        0.667833      0.748766       0.464615       21.2916   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "6                   250.781                 15.714         NaN  \n",
       "13                  263.268                 16.497         NaN  \n",
       "21                  255.059                 15.982         NaN  \n",
       "28                  254.843                 15.969         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store validation metrics in dataframe\n",
    "val_history = log_history[log_history['eval_f1'].notna()]\n",
    "val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "978bf0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_x</th>\n",
       "      <th>learning_rate_x</th>\n",
       "      <th>epoch_x</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_x</th>\n",
       "      <th>train_f1_x</th>\n",
       "      <th>train_recall_x</th>\n",
       "      <th>train_precision_x</th>\n",
       "      <th>train_roc_auc_x</th>\n",
       "      <th>train_accuracy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss_y</th>\n",
       "      <th>eval_f1_y</th>\n",
       "      <th>eval_recall_y</th>\n",
       "      <th>eval_precision_y</th>\n",
       "      <th>eval_roc_auc_y</th>\n",
       "      <th>eval_accuracy_y</th>\n",
       "      <th>eval_runtime_y</th>\n",
       "      <th>eval_samples_per_second_y</th>\n",
       "      <th>eval_steps_per_second_y</th>\n",
       "      <th>total_flos_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.448443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>0.552714</td>\n",
       "      <td>0.458934</td>\n",
       "      <td>0.694662</td>\n",
       "      <td>0.725046</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>21.6364</td>\n",
       "      <td>250.781</td>\n",
       "      <td>15.714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.533984</td>\n",
       "      <td>0.775142</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.502557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.570467</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.734689</td>\n",
       "      <td>0.448397</td>\n",
       "      <td>20.6102</td>\n",
       "      <td>263.268</td>\n",
       "      <td>16.497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.695043</td>\n",
       "      <td>0.612149</td>\n",
       "      <td>0.803901</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.575640</td>\n",
       "      <td>0.498903</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>0.744312</td>\n",
       "      <td>0.458164</td>\n",
       "      <td>21.2735</td>\n",
       "      <td>255.059</td>\n",
       "      <td>15.982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.058027</td>\n",
       "      <td>0.732053</td>\n",
       "      <td>0.655205</td>\n",
       "      <td>0.829324</td>\n",
       "      <td>0.824644</td>\n",
       "      <td>0.614633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.667833</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.464615</td>\n",
       "      <td>21.2916</td>\n",
       "      <td>254.843</td>\n",
       "      <td>15.969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_x  learning_rate_x  epoch_x   step  train_loss_x  train_f1_x  \\\n",
       "0     NaN              NaN      1.0   2713      0.086467    0.572314   \n",
       "1     NaN              NaN      2.0   5426      0.073168    0.632351   \n",
       "2     NaN              NaN      3.0   8139      0.063692    0.695043   \n",
       "3     NaN              NaN      4.0  10852      0.058027    0.732053   \n",
       "\n",
       "   train_recall_x  train_precision_x  train_roc_auc_x  train_accuracy_x  ...  \\\n",
       "0        0.475273           0.719151         0.733564          0.448443  ...   \n",
       "1        0.533984           0.775142         0.763593          0.502557  ...   \n",
       "2        0.612149           0.803901         0.802798          0.571600  ...   \n",
       "3        0.655205           0.829324         0.824644          0.614633  ...   \n",
       "\n",
       "   eval_loss_y  eval_f1_y  eval_recall_y  eval_precision_y  eval_roc_auc_y  \\\n",
       "0     0.090692   0.552714       0.458934          0.694662        0.725046   \n",
       "1     0.084908   0.570467       0.478056          0.707164        0.734689   \n",
       "2     0.084577   0.575640       0.498903          0.680274        0.744312   \n",
       "3     0.085617   0.577454       0.508621          0.667833        0.748766   \n",
       "\n",
       "   eval_accuracy_y  eval_runtime_y  eval_samples_per_second_y  \\\n",
       "0         0.434021         21.6364                    250.781   \n",
       "1         0.448397         20.6102                    263.268   \n",
       "2         0.458164         21.2735                    255.059   \n",
       "3         0.464615         21.2916                    254.843   \n",
       "\n",
       "   eval_steps_per_second_y  total_flos_y  \n",
       "0                   15.714           NaN  \n",
       "1                   16.497           NaN  \n",
       "2                   15.982           NaN  \n",
       "3                   15.969           NaN  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.merge(train_history, val_history, on='step', how='outer')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ebe0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function to check for accuracy with graphs \n",
    "def plot_model_performance(history):\n",
    "\n",
    "    #getting train and validation accuracy\n",
    "    acc = history['train_accuracy_x']\n",
    "    val_acc = history['eval_accuracy_y']\n",
    "\n",
    "    #getting train and validation loss\n",
    "    loss = history['train_loss_x']\n",
    "    val_loss = history['eval_loss_y']\n",
    "\n",
    "    epochs_range = range(4)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97c350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7fb89",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5456e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate the model on the test set\n",
    "def evaluate_model(test_dataset):\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7bb617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08423807471990585, 'eval_f1': 0.5817888799355359, 'eval_recall': 0.5133512403223258, 'eval_precision': 0.6712809917355372, 'eval_roc_auc': 0.7512130342395962, 'eval_accuracy': 0.47447945457895707, 'eval_runtime': 15.8501, 'eval_samples_per_second': 342.394, 'eval_steps_per_second': 21.451, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c172305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78c37071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(trainer, test_dataset, target_cols):\n",
    "    y_test = trainer.predict(test_dataset)\n",
    "    threshold = 0.5\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(y_test.predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    \n",
    "    # finally, compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "794fec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.581789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.513351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.671281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.751213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.474479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.581789\n",
       "recall     0.513351\n",
       "precision  0.671281\n",
       "roc_auc    0.751213\n",
       "accuracy   0.474479"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.662</td>\n",
       "      <td>504</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.793</td>\n",
       "      <td>264</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.454</td>\n",
       "      <td>198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.248</td>\n",
       "      <td>320</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.378</td>\n",
       "      <td>351</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.449</td>\n",
       "      <td>135</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.418</td>\n",
       "      <td>153</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.433</td>\n",
       "      <td>284</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.527</td>\n",
       "      <td>83</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.292</td>\n",
       "      <td>151</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.355</td>\n",
       "      <td>267</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.485</td>\n",
       "      <td>123</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.586</td>\n",
       "      <td>37</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.408</td>\n",
       "      <td>103</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.700</td>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.920</td>\n",
       "      <td>352</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.598</td>\n",
       "      <td>161</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.814</td>\n",
       "      <td>238</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.147</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.540</td>\n",
       "      <td>186</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.262</td>\n",
       "      <td>145</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.626</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.593</td>\n",
       "      <td>156</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.565</td>\n",
       "      <td>141</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.486</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.943      0.687   0.700  0.694  0.662      504        0.5\n",
       "amusement          0.980      0.768   0.841  0.803  0.793      264        0.5\n",
       "anger              0.966      0.556   0.399  0.465  0.454      198        0.5\n",
       "annoyance          0.937      0.420   0.181  0.253  0.248      320        0.5\n",
       "approval           0.938      0.531   0.313  0.394  0.378      351        0.5\n",
       "caring             0.977      0.541   0.393  0.455  0.449      135        0.5\n",
       "confusion          0.973      0.519   0.359  0.425  0.418      153        0.5\n",
       "curiosity          0.948      0.504   0.419  0.458  0.433      284        0.5\n",
       "desire             0.988      0.673   0.422  0.519  0.527       83        0.5\n",
       "disappointment     0.973      0.571   0.159  0.249  0.292      151        0.5\n",
       "disapproval        0.946      0.435   0.337  0.380  0.355      267        0.5\n",
       "disgust            0.980      0.602   0.407  0.485  0.485      123        0.5\n",
       "embarrassment      0.995      0.800   0.432  0.561  0.586       37        0.5\n",
       "excitement         0.982      0.574   0.301  0.395  0.408      103        0.5\n",
       "fear               0.991      0.691   0.718  0.704  0.700       78        0.5\n",
       "gratitude          0.990      0.944   0.906  0.925  0.920      352        0.5\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.5\n",
       "joy                0.979      0.685   0.540  0.604  0.598      161        0.5\n",
       "love               0.984      0.793   0.853  0.822  0.814      238        0.5\n",
       "nervousness        0.996      0.500   0.043  0.080  0.147       23        0.5\n",
       "optimism           0.973      0.640   0.478  0.548  0.540      186        0.5\n",
       "pride              0.997      0.000   0.000  0.000  0.000       16        0.5\n",
       "realization        0.973      0.469   0.159  0.237  0.262      145        0.5\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.5\n",
       "remorse            0.992      0.585   0.679  0.628  0.626       56        0.5\n",
       "sadness            0.979      0.669   0.545  0.601  0.593      156        0.5\n",
       "surprise           0.979      0.606   0.546  0.575  0.565      141        0.5\n",
       "neutral            0.783      0.728   0.546  0.624  0.486     1787        0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, outputs = calc_test_metrics(trainer, test_dataset, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual     Predicted\n",
      "0     [sadness]        [love]\n",
      "1  [admiration]  [admiration]\n",
      "2  [excitement]    [optimism]\n",
      "3   [gratitude]   [gratitude]\n",
      "4     [neutral]     [neutral]\n",
      "5   [gratitude]   [gratitude]\n",
      "6   [gratitude]   [gratitude]\n",
      "7   [gratitude]   [gratitude]\n",
      "8     [remorse]     [sadness]\n",
      "9     [sadness]     [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(outputs[i])[0]) for i in range(len(outputs))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0                [love]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53492f7a",
   "metadata": {},
   "source": [
    "## 4. Save the output, tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('output_roberta_m3.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./roberta_M3_transformer/')\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./roberta_M3_transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
