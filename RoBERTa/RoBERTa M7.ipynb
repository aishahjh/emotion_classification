{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Roberta M7 (with WordNet augmented data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdb5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "import copy\n",
    "from typing import Optional\n",
    "from torch import FloatTensor\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading wordnet augmented dataset into train dataset\n",
    "\n",
    "df_train = pd.read_csv('data/clean/augmented/augmented_wordnet_subs_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46926bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4af580be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43261378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffe4fe",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7c54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3d783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training set\n",
    "train_encodings = tokenizer(list(df_train['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],\n",
    "                                   'attention_mask': train_encodings['attention_mask'],\n",
    "                                   'labels': torch.tensor(df_train[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "# Tokenize the validation set\n",
    "val_encodings = tokenizer(list(df_val['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "valid_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],\n",
    "                                 'attention_mask': val_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_val[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(list(df_test['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],\n",
    "                                 'attention_mask': test_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_test[target_cols].values, dtype=torch.float32)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4840",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0442a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download model from model hub\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(target_cols))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e91901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom callback to get train and validation info during training\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb5596",
   "metadata": {},
   "source": [
    "#### Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cdb39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "num_classes = len(target_cols)\n",
    "class_counts = np.sum(train_dataset['labels'], axis=0)\n",
    "class_weights = 1.0 / class_counts\n",
    "\n",
    "# Normalize weights\n",
    "class_weights /= class_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82eeccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00434095, 0.00770108, 0.01144105, 0.00725835, 0.00610007,\n",
       "       0.01649321, 0.01310535, 0.00818262, 0.02796899, 0.0141389 ,\n",
       "       0.00886653, 0.02260797, 0.05936463, 0.02101773, 0.03013129,\n",
       "       0.00673483, 0.23283272, 0.01234719, 0.0085945 , 0.10998846,\n",
       "       0.01133973, 0.16151459, 0.01615146, 0.11717725, 0.03289563,\n",
       "       0.01353066, 0.01691332, 0.00126095])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "611e9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom trainer to incorporate class weights\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights: Optional[FloatTensor] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            class_weights = class_weights.to(self.args.device)\n",
    "            logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
    "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        try:\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1,model.num_labels))\n",
    "        except AttributeError:  # DataParallel\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1, model.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1980801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='data/output/',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_dir=\"data/output/logs\",\n",
    "    learning_rate=float(LEARNING_RATE),\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0eae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to calculate the metrics for multi label classification\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3287773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Trainer instance\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.add_callback(CustomCallback(trainer)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e1c6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishah/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10852' max='10852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10852/10852 1:35:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>0.471124</td>\n",
       "      <td>0.352428</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.338163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.096013</td>\n",
       "      <td>0.483615</td>\n",
       "      <td>0.363166</td>\n",
       "      <td>0.723610</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>0.345558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.461964</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>0.441048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0.531952</td>\n",
       "      <td>0.426646</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.403981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.651677</td>\n",
       "      <td>0.555884</td>\n",
       "      <td>0.787360</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.525479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.558226</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.438260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.701329</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.581621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.561554</td>\n",
       "      <td>0.482602</td>\n",
       "      <td>0.671391</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>0.441762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10852, training_loss=0.09582081203130265, metrics={'train_runtime': 5709.9611, 'train_samples_per_second': 30.409, 'train_steps_per_second': 1.901, 'total_flos': 1.865290854378547e+16, 'train_loss': 0.09582081203130265, 'epoch': 4.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dffa6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.18</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>0.471124</td>\n",
       "      <td>0.352428</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.338163</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096013</td>\n",
       "      <td>0.483615</td>\n",
       "      <td>0.363166</td>\n",
       "      <td>0.723610</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>0.345558</td>\n",
       "      <td>20.6901</td>\n",
       "      <td>262.251</td>\n",
       "      <td>16.433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.461964</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>0.441048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0.531952</td>\n",
       "      <td>0.426646</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.403981</td>\n",
       "      <td>20.3567</td>\n",
       "      <td>266.547</td>\n",
       "      <td>16.702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.21</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.58</td>\n",
       "      <td>7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.76</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.95</td>\n",
       "      <td>8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.651677</td>\n",
       "      <td>0.555884</td>\n",
       "      <td>0.787360</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.525479</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.558226</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.438260</td>\n",
       "      <td>20.4386</td>\n",
       "      <td>265.478</td>\n",
       "      <td>16.635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.13</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.69</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.87</td>\n",
       "      <td>10500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.701329</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.581621</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.561554</td>\n",
       "      <td>0.482602</td>\n",
       "      <td>0.671391</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>0.441762</td>\n",
       "      <td>20.1945</td>\n",
       "      <td>268.687</td>\n",
       "      <td>16.836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.095821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.865291e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "0   0.1598       0.000048   0.18    500         NaN       NaN           NaN   \n",
       "1   0.1311       0.000045   0.37   1000         NaN       NaN           NaN   \n",
       "2   0.1220       0.000043   0.55   1500         NaN       NaN           NaN   \n",
       "3   0.1128       0.000041   0.74   2000         NaN       NaN           NaN   \n",
       "4   0.1088       0.000038   0.92   2500         NaN       NaN           NaN   \n",
       "5      NaN            NaN   1.00   2713    0.098955  0.471124      0.352428   \n",
       "6      NaN            NaN   1.00   2713         NaN       NaN           NaN   \n",
       "7   0.1033       0.000036   1.11   3000         NaN       NaN           NaN   \n",
       "8   0.1003       0.000034   1.29   3500         NaN       NaN           NaN   \n",
       "9   0.0986       0.000032   1.47   4000         NaN       NaN           NaN   \n",
       "10  0.0961       0.000029   1.66   4500         NaN       NaN           NaN   \n",
       "11  0.0967       0.000027   1.84   5000         NaN       NaN           NaN   \n",
       "12     NaN            NaN   2.00   5426    0.083372  0.572680      0.461964   \n",
       "13     NaN            NaN   2.00   5426         NaN       NaN           NaN   \n",
       "14  0.0929       0.000025   2.03   5500         NaN       NaN           NaN   \n",
       "15  0.0873       0.000022   2.21   6000         NaN       NaN           NaN   \n",
       "16  0.0847       0.000020   2.40   6500         NaN       NaN           NaN   \n",
       "17  0.0859       0.000018   2.58   7000         NaN       NaN           NaN   \n",
       "18  0.0844       0.000015   2.76   7500         NaN       NaN           NaN   \n",
       "19  0.0859       0.000013   2.95   8000         NaN       NaN           NaN   \n",
       "20     NaN            NaN   3.00   8139    0.071479  0.651677      0.555884   \n",
       "21     NaN            NaN   3.00   8139         NaN       NaN           NaN   \n",
       "22  0.0788       0.000011   3.13   8500         NaN       NaN           NaN   \n",
       "23  0.0741       0.000009   3.32   9000         NaN       NaN           NaN   \n",
       "24  0.0753       0.000006   3.50   9500         NaN       NaN           NaN   \n",
       "25  0.0738       0.000004   3.69  10000         NaN       NaN           NaN   \n",
       "26  0.0750       0.000002   3.87  10500         NaN       NaN           NaN   \n",
       "27     NaN            NaN   4.00  10852    0.064193  0.701329      0.613637   \n",
       "28     NaN            NaN   4.00  10852         NaN       NaN           NaN   \n",
       "29     NaN            NaN   4.00  10852    0.095821       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "0               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "1               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "2               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "3               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "4               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "5          0.710375       0.673061        0.338163  ...        NaN       NaN   \n",
       "6               NaN            NaN             NaN  ...   0.096013  0.483615   \n",
       "7               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "8               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "9               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "10              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "11              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "12         0.753191       0.727661        0.441048  ...        NaN       NaN   \n",
       "13              NaN            NaN             NaN  ...   0.088122  0.531952   \n",
       "14              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "15              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "16              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "17              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "18              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "19              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "20         0.787360       0.774648        0.525479  ...        NaN       NaN   \n",
       "21              NaN            NaN             NaN  ...   0.086437  0.558226   \n",
       "22              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "23              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "24              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "25              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "26              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "27         0.818262       0.803828        0.581621  ...        NaN       NaN   \n",
       "28              NaN            NaN             NaN  ...   0.087241  0.561554   \n",
       "29              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "0           NaN             NaN           NaN            NaN           NaN   \n",
       "1           NaN             NaN           NaN            NaN           NaN   \n",
       "2           NaN             NaN           NaN            NaN           NaN   \n",
       "3           NaN             NaN           NaN            NaN           NaN   \n",
       "4           NaN             NaN           NaN            NaN           NaN   \n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "6      0.363166        0.723610      0.678543       0.345558       20.6901   \n",
       "7           NaN             NaN           NaN            NaN           NaN   \n",
       "8           NaN             NaN           NaN            NaN           NaN   \n",
       "9           NaN             NaN           NaN            NaN           NaN   \n",
       "10          NaN             NaN           NaN            NaN           NaN   \n",
       "11          NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "13     0.426646        0.706279      0.709434       0.403981       20.3567   \n",
       "14          NaN             NaN           NaN            NaN           NaN   \n",
       "15          NaN             NaN           NaN            NaN           NaN   \n",
       "16          NaN             NaN           NaN            NaN           NaN   \n",
       "17          NaN             NaN           NaN            NaN           NaN   \n",
       "18          NaN             NaN           NaN            NaN           NaN   \n",
       "19          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "21     0.469592        0.688103      0.730131       0.438260       20.4386   \n",
       "22          NaN             NaN           NaN            NaN           NaN   \n",
       "23          NaN             NaN           NaN            NaN           NaN   \n",
       "24          NaN             NaN           NaN            NaN           NaN   \n",
       "25          NaN             NaN           NaN            NaN           NaN   \n",
       "26          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "28     0.482602        0.671391      0.736124       0.441762       20.1945   \n",
       "29          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second    total_flos  \n",
       "0                       NaN                    NaN           NaN  \n",
       "1                       NaN                    NaN           NaN  \n",
       "2                       NaN                    NaN           NaN  \n",
       "3                       NaN                    NaN           NaN  \n",
       "4                       NaN                    NaN           NaN  \n",
       "5                       NaN                    NaN           NaN  \n",
       "6                   262.251                 16.433           NaN  \n",
       "7                       NaN                    NaN           NaN  \n",
       "8                       NaN                    NaN           NaN  \n",
       "9                       NaN                    NaN           NaN  \n",
       "10                      NaN                    NaN           NaN  \n",
       "11                      NaN                    NaN           NaN  \n",
       "12                      NaN                    NaN           NaN  \n",
       "13                  266.547                 16.702           NaN  \n",
       "14                      NaN                    NaN           NaN  \n",
       "15                      NaN                    NaN           NaN  \n",
       "16                      NaN                    NaN           NaN  \n",
       "17                      NaN                    NaN           NaN  \n",
       "18                      NaN                    NaN           NaN  \n",
       "19                      NaN                    NaN           NaN  \n",
       "20                      NaN                    NaN           NaN  \n",
       "21                  265.478                 16.635           NaN  \n",
       "22                      NaN                    NaN           NaN  \n",
       "23                      NaN                    NaN           NaN  \n",
       "24                      NaN                    NaN           NaN  \n",
       "25                      NaN                    NaN           NaN  \n",
       "26                      NaN                    NaN           NaN  \n",
       "27                      NaN                    NaN           NaN  \n",
       "28                  268.687                 16.836           NaN  \n",
       "29                      NaN                    NaN  1.865291e+16  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view train and validation metrics from training\n",
    "log_history = pd.DataFrame(trainer.state.log_history)\n",
    "log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf0d198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>0.471124</td>\n",
       "      <td>0.352428</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.338163</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.461964</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>0.441048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.651677</td>\n",
       "      <td>0.555884</td>\n",
       "      <td>0.787360</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.525479</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.701329</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.581621</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "5    NaN            NaN    1.0   2713    0.098955  0.471124      0.352428   \n",
       "12   NaN            NaN    2.0   5426    0.083372  0.572680      0.461964   \n",
       "20   NaN            NaN    3.0   8139    0.071479  0.651677      0.555884   \n",
       "27   NaN            NaN    4.0  10852    0.064193  0.701329      0.613637   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss  eval_f1  \\\n",
       "5          0.710375       0.673061        0.338163  ...        NaN      NaN   \n",
       "12         0.753191       0.727661        0.441048  ...        NaN      NaN   \n",
       "20         0.787360       0.774648        0.525479  ...        NaN      NaN   \n",
       "27         0.818262       0.803828        0.581621  ...        NaN      NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "5                       NaN                    NaN         NaN  \n",
       "12                      NaN                    NaN         NaN  \n",
       "20                      NaN                    NaN         NaN  \n",
       "27                      NaN                    NaN         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store train metrics in dataframe\n",
    "train_history = log_history[log_history['train_f1'].notna()]\n",
    "train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97eea248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096013</td>\n",
       "      <td>0.483615</td>\n",
       "      <td>0.363166</td>\n",
       "      <td>0.723610</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>0.345558</td>\n",
       "      <td>20.6901</td>\n",
       "      <td>262.251</td>\n",
       "      <td>16.433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0.531952</td>\n",
       "      <td>0.426646</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.403981</td>\n",
       "      <td>20.3567</td>\n",
       "      <td>266.547</td>\n",
       "      <td>16.702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.558226</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.438260</td>\n",
       "      <td>20.4386</td>\n",
       "      <td>265.478</td>\n",
       "      <td>16.635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.561554</td>\n",
       "      <td>0.482602</td>\n",
       "      <td>0.671391</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>0.441762</td>\n",
       "      <td>20.1945</td>\n",
       "      <td>268.687</td>\n",
       "      <td>16.836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "6    NaN            NaN    1.0   2713         NaN       NaN           NaN   \n",
       "13   NaN            NaN    2.0   5426         NaN       NaN           NaN   \n",
       "21   NaN            NaN    3.0   8139         NaN       NaN           NaN   \n",
       "28   NaN            NaN    4.0  10852         NaN       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "6               NaN            NaN             NaN  ...   0.096013  0.483615   \n",
       "13              NaN            NaN             NaN  ...   0.088122  0.531952   \n",
       "21              NaN            NaN             NaN  ...   0.086437  0.558226   \n",
       "28              NaN            NaN             NaN  ...   0.087241  0.561554   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "6      0.363166        0.723610      0.678543       0.345558       20.6901   \n",
       "13     0.426646        0.706279      0.709434       0.403981       20.3567   \n",
       "21     0.469592        0.688103      0.730131       0.438260       20.4386   \n",
       "28     0.482602        0.671391      0.736124       0.441762       20.1945   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "6                   262.251                 16.433         NaN  \n",
       "13                  266.547                 16.702         NaN  \n",
       "21                  265.478                 16.635         NaN  \n",
       "28                  268.687                 16.836         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store val metrics in dataframe\n",
    "val_history = log_history[log_history['eval_f1'].notna()]\n",
    "val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "978bf0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_x</th>\n",
       "      <th>learning_rate_x</th>\n",
       "      <th>epoch_x</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_x</th>\n",
       "      <th>train_f1_x</th>\n",
       "      <th>train_recall_x</th>\n",
       "      <th>train_precision_x</th>\n",
       "      <th>train_roc_auc_x</th>\n",
       "      <th>train_accuracy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss_y</th>\n",
       "      <th>eval_f1_y</th>\n",
       "      <th>eval_recall_y</th>\n",
       "      <th>eval_precision_y</th>\n",
       "      <th>eval_roc_auc_y</th>\n",
       "      <th>eval_accuracy_y</th>\n",
       "      <th>eval_runtime_y</th>\n",
       "      <th>eval_samples_per_second_y</th>\n",
       "      <th>eval_steps_per_second_y</th>\n",
       "      <th>total_flos_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>0.471124</td>\n",
       "      <td>0.352428</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.338163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096013</td>\n",
       "      <td>0.483615</td>\n",
       "      <td>0.363166</td>\n",
       "      <td>0.723610</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>0.345558</td>\n",
       "      <td>20.6901</td>\n",
       "      <td>262.251</td>\n",
       "      <td>16.433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.461964</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>0.441048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0.531952</td>\n",
       "      <td>0.426646</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.403981</td>\n",
       "      <td>20.3567</td>\n",
       "      <td>266.547</td>\n",
       "      <td>16.702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.651677</td>\n",
       "      <td>0.555884</td>\n",
       "      <td>0.787360</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.525479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.558226</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.438260</td>\n",
       "      <td>20.4386</td>\n",
       "      <td>265.478</td>\n",
       "      <td>16.635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.701329</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.581621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.561554</td>\n",
       "      <td>0.482602</td>\n",
       "      <td>0.671391</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>0.441762</td>\n",
       "      <td>20.1945</td>\n",
       "      <td>268.687</td>\n",
       "      <td>16.836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_x  learning_rate_x  epoch_x   step  train_loss_x  train_f1_x  \\\n",
       "0     NaN              NaN      1.0   2713      0.098955    0.471124   \n",
       "1     NaN              NaN      2.0   5426      0.083372    0.572680   \n",
       "2     NaN              NaN      3.0   8139      0.071479    0.651677   \n",
       "3     NaN              NaN      4.0  10852      0.064193    0.701329   \n",
       "\n",
       "   train_recall_x  train_precision_x  train_roc_auc_x  train_accuracy_x  ...  \\\n",
       "0        0.352428           0.710375         0.673061          0.338163  ...   \n",
       "1        0.461964           0.753191         0.727661          0.441048  ...   \n",
       "2        0.555884           0.787360         0.774648          0.525479  ...   \n",
       "3        0.613637           0.818262         0.803828          0.581621  ...   \n",
       "\n",
       "   eval_loss_y  eval_f1_y  eval_recall_y  eval_precision_y  eval_roc_auc_y  \\\n",
       "0     0.096013   0.483615       0.363166          0.723610        0.678543   \n",
       "1     0.088122   0.531952       0.426646          0.706279        0.709434   \n",
       "2     0.086437   0.558226       0.469592          0.688103        0.730131   \n",
       "3     0.087241   0.561554       0.482602          0.671391        0.736124   \n",
       "\n",
       "   eval_accuracy_y  eval_runtime_y  eval_samples_per_second_y  \\\n",
       "0         0.345558         20.6901                    262.251   \n",
       "1         0.403981         20.3567                    266.547   \n",
       "2         0.438260         20.4386                    265.478   \n",
       "3         0.441762         20.1945                    268.687   \n",
       "\n",
       "   eval_steps_per_second_y  total_flos_y  \n",
       "0                   16.433           NaN  \n",
       "1                   16.702           NaN  \n",
       "2                   16.635           NaN  \n",
       "3                   16.836           NaN  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.merge(train_history, val_history, on='step', how='outer')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ebe0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function to check for accuracy with graphs \n",
    "def plot_model_performance(history):\n",
    "\n",
    "    #getting train and validation accuracy\n",
    "    acc = history['train_accuracy_x']\n",
    "    val_acc = history['eval_accuracy_y']\n",
    "\n",
    "    #getting train and validation loss\n",
    "    loss = history['train_loss_x']\n",
    "    val_loss = history['eval_loss_y']\n",
    "\n",
    "    epochs_range = range(4)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c97c350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7fb89",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5456e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate the model on the test set\n",
    "def evaluate_model(test_dataset):\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7bb617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0857628658413887, 'eval_f1': 0.5683552450124115, 'eval_recall': 0.4883867909622373, 'eval_precision': 0.6796394019349165, 'eval_roc_auc': 0.7391908890777731, 'eval_accuracy': 0.45513174866408695, 'eval_runtime': 15.9813, 'eval_samples_per_second': 339.585, 'eval_steps_per_second': 21.275, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c172305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78c37071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(trainer, test_dataset, target_cols):\n",
    "    y_test = trainer.predict(test_dataset)\n",
    "    threshold = 0.5\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(y_test.predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    \n",
    "    # finally, compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794fec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.568355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.488387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.679639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.739191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.455132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.568355\n",
       "recall     0.488387\n",
       "precision  0.679639\n",
       "roc_auc    0.739191\n",
       "accuracy   0.455132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.645</td>\n",
       "      <td>504</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.805</td>\n",
       "      <td>264</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.443</td>\n",
       "      <td>198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.239</td>\n",
       "      <td>320</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.386</td>\n",
       "      <td>351</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.393</td>\n",
       "      <td>135</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.386</td>\n",
       "      <td>153</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.374</td>\n",
       "      <td>284</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.414</td>\n",
       "      <td>83</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.195</td>\n",
       "      <td>151</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.361</td>\n",
       "      <td>267</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.457</td>\n",
       "      <td>123</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.564</td>\n",
       "      <td>37</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.373</td>\n",
       "      <td>103</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.662</td>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.917</td>\n",
       "      <td>352</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.569</td>\n",
       "      <td>161</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.807</td>\n",
       "      <td>238</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.207</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.538</td>\n",
       "      <td>186</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.374</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.233</td>\n",
       "      <td>145</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.653</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.562</td>\n",
       "      <td>156</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.563</td>\n",
       "      <td>141</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.939      0.669   0.688  0.678  0.645      504        0.5\n",
       "amusement          0.980      0.760   0.875  0.813  0.805      264        0.5\n",
       "anger              0.966      0.538   0.394  0.455  0.443      198        0.5\n",
       "annoyance          0.941      0.494   0.138  0.215  0.239      320        0.5\n",
       "approval           0.940      0.578   0.296  0.392  0.386      351        0.5\n",
       "caring             0.976      0.525   0.311  0.391  0.393      135        0.5\n",
       "confusion          0.973      0.529   0.301  0.383  0.386      153        0.5\n",
       "curiosity          0.948      0.500   0.320  0.391  0.374      284        0.5\n",
       "desire             0.986      0.565   0.313  0.403  0.414       83        0.5\n",
       "disappointment     0.972      0.452   0.093  0.154  0.195      151        0.5\n",
       "disapproval        0.950      0.494   0.300  0.373  0.361      267        0.5\n",
       "disgust            0.980      0.582   0.374  0.455  0.457      123        0.5\n",
       "embarrassment      0.995      0.789   0.405  0.536  0.564       37        0.5\n",
       "excitement         0.981      0.518   0.282  0.365  0.373      103        0.5\n",
       "fear               0.990      0.667   0.667  0.667  0.662       78        0.5\n",
       "gratitude          0.990      0.936   0.909  0.922  0.917      352        0.5\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.5\n",
       "joy                0.977      0.639   0.528  0.578  0.569      161        0.5\n",
       "love               0.983      0.788   0.845  0.815  0.807      238        0.5\n",
       "nervousness        0.996      0.500   0.087  0.148  0.207       23        0.5\n",
       "optimism           0.973      0.629   0.484  0.547  0.538      186        0.5\n",
       "pride              0.997      0.750   0.188  0.300  0.374       16        0.5\n",
       "realization        0.972      0.412   0.145  0.214  0.233      145        0.5\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.5\n",
       "remorse            0.992      0.619   0.696  0.655  0.653       56        0.5\n",
       "sadness            0.978      0.664   0.494  0.566  0.562      156        0.5\n",
       "surprise           0.980      0.660   0.496  0.567  0.563      141        0.5\n",
       "neutral            0.782      0.736   0.525  0.613  0.480     1787        0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, outputs = calc_test_metrics(trainer, test_dataset, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]                   [love]\n",
      "1  [admiration]             [admiration]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]                [remorse]\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(outputs[i])[0]) for i in range(len(outputs))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0                [love]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53492f7a",
   "metadata": {},
   "source": [
    "## 4. Save the output, tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('output_roberta_m7.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./roberta_M7_transformer/')\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./roberta_M7_transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
