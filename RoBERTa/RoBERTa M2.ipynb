{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Roberta M2 (with class weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplo# Roberta M1 (with class weight)\n",
    "\n",
    "Importing the necessary librariest as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "import copy\n",
    "from typing import Optional\n",
    "from torch import FloatTensor\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d73c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  admiration  amusement  \\\n",
       "0  my favourite food is anything i did not have t...           0          0   \n",
       "1  now if he does off himself everyone will think...           0          0   \n",
       "2                     why the fuck is bayless isoing           0          0   \n",
       "3                        to make her feel threatened           0          0   \n",
       "4                             dirty southern wankers           0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
       "0      0          0         0       0          0          0       0  ...   \n",
       "1      0          0         0       0          0          0       0  ...   \n",
       "2      1          0         0       0          0          0       0  ...   \n",
       "3      0          0         0       0          0          0       0  ...   \n",
       "4      0          1         0       0          0          0       0  ...   \n",
       "\n",
       "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0     0            0         0      0            0       0        0        0   \n",
       "1     0            0         0      0            0       0        0        0   \n",
       "2     0            0         0      0            0       0        0        0   \n",
       "3     0            0         0      0            0       0        0        0   \n",
       "4     0            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46926bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af580be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43261378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffe4fe",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7c54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3d783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training set\n",
    "train_encodings = tokenizer(list(df_train['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],\n",
    "                                   'attention_mask': train_encodings['attention_mask'],\n",
    "                                   'labels': torch.tensor(df_train[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "# Tokenize the validation set\n",
    "val_encodings = tokenizer(list(df_val['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "valid_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],\n",
    "                                 'attention_mask': val_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_val[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(list(df_test['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],\n",
    "                                 'attention_mask': test_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_test[target_cols].values, dtype=torch.float32)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4840",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0442a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download model from model hub\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(target_cols))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e91901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom callback to get train and validation info during training\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb5596",
   "metadata": {},
   "source": [
    "#### Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdb39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "num_classes = len(target_cols)\n",
    "class_counts = np.sum(train_dataset['labels'], axis=0)\n",
    "class_weights = 1.0 / class_counts\n",
    "\n",
    "# Normalize weights\n",
    "class_weights /= class_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82eeccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00434095, 0.00770108, 0.01144105, 0.00725835, 0.00610007,\n",
       "       0.01649321, 0.01310535, 0.00818262, 0.02796899, 0.0141389 ,\n",
       "       0.00886653, 0.02260797, 0.05936463, 0.02101773, 0.03013129,\n",
       "       0.00673483, 0.23283272, 0.01234719, 0.0085945 , 0.10998846,\n",
       "       0.01133973, 0.16151459, 0.01615146, 0.11717725, 0.03289563,\n",
       "       0.01353066, 0.01691332, 0.00126095])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611e9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom trainer to incorporate class weights\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights: Optional[FloatTensor] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            class_weights = class_weights.to(self.args.device)\n",
    "            logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
    "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        try:\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1,model.num_labels))\n",
    "        except AttributeError:  # DataParallel\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1, model.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1980801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='data/output/',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_dir=\"data/output/logs\",\n",
    "    learning_rate=float(LEARNING_RATE),\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0eae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to calculate the metrics for multi label classification\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3287773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Trainer instance\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.add_callback(CustomCallback(trainer)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e1c6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishah/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10852' max='10852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10852/10852 1:42:28, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.563055</td>\n",
       "      <td>0.462101</td>\n",
       "      <td>0.720449</td>\n",
       "      <td>0.727116</td>\n",
       "      <td>0.437707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.090329</td>\n",
       "      <td>0.544464</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.698136</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.427387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>0.628388</td>\n",
       "      <td>0.532027</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.496429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.085440</td>\n",
       "      <td>0.561915</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.696660</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>0.437707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.618275</td>\n",
       "      <td>0.808124</td>\n",
       "      <td>0.805916</td>\n",
       "      <td>0.574318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.085390</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.502351</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>0.462403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.748315</td>\n",
       "      <td>0.678005</td>\n",
       "      <td>0.834896</td>\n",
       "      <td>0.836060</td>\n",
       "      <td>0.631957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.514107</td>\n",
       "      <td>0.660757</td>\n",
       "      <td>0.751268</td>\n",
       "      <td>0.467011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10852, training_loss=0.08469479961936605, metrics={'train_runtime': 6150.0542, 'train_samples_per_second': 28.233, 'train_steps_per_second': 1.765, 'total_flos': 1.8563660177547264e+16, 'train_loss': 0.08469479961936605, 'epoch': 4.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dffa6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.18</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.563055</td>\n",
       "      <td>0.462101</td>\n",
       "      <td>0.720449</td>\n",
       "      <td>0.727116</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090329</td>\n",
       "      <td>0.544464</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.698136</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.427387</td>\n",
       "      <td>21.7372</td>\n",
       "      <td>249.619</td>\n",
       "      <td>15.641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>0.628388</td>\n",
       "      <td>0.532027</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085440</td>\n",
       "      <td>0.561915</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.696660</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>20.1700</td>\n",
       "      <td>269.014</td>\n",
       "      <td>16.857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.21</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.58</td>\n",
       "      <td>7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.76</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.95</td>\n",
       "      <td>8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.618275</td>\n",
       "      <td>0.808124</td>\n",
       "      <td>0.805916</td>\n",
       "      <td>0.574318</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085390</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.502351</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>0.462403</td>\n",
       "      <td>21.0338</td>\n",
       "      <td>257.965</td>\n",
       "      <td>16.164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.13</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.69</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.87</td>\n",
       "      <td>10500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.748315</td>\n",
       "      <td>0.678005</td>\n",
       "      <td>0.834896</td>\n",
       "      <td>0.836060</td>\n",
       "      <td>0.631957</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.514107</td>\n",
       "      <td>0.660757</td>\n",
       "      <td>0.751268</td>\n",
       "      <td>0.467011</td>\n",
       "      <td>102.8424</td>\n",
       "      <td>52.760</td>\n",
       "      <td>3.306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.084695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.856366e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "0   0.1560       0.000048   0.18    500         NaN       NaN           NaN   \n",
       "1   0.1162       0.000045   0.37   1000         NaN       NaN           NaN   \n",
       "2   0.1074       0.000043   0.55   1500         NaN       NaN           NaN   \n",
       "3   0.0992       0.000041   0.74   2000         NaN       NaN           NaN   \n",
       "4   0.0958       0.000038   0.92   2500         NaN       NaN           NaN   \n",
       "5      NaN            NaN   1.00   2713    0.086619  0.563055      0.462101   \n",
       "6      NaN            NaN   1.00   2713         NaN       NaN           NaN   \n",
       "7   0.0912       0.000036   1.11   3000         NaN       NaN           NaN   \n",
       "8   0.0885       0.000034   1.29   3500         NaN       NaN           NaN   \n",
       "9   0.0867       0.000032   1.47   4000         NaN       NaN           NaN   \n",
       "10  0.0845       0.000029   1.66   4500         NaN       NaN           NaN   \n",
       "11  0.0853       0.000027   1.84   5000         NaN       NaN           NaN   \n",
       "12     NaN            NaN   2.00   5426    0.073567  0.628388      0.532027   \n",
       "13     NaN            NaN   2.00   5426         NaN       NaN           NaN   \n",
       "14  0.0820       0.000025   2.03   5500         NaN       NaN           NaN   \n",
       "15  0.0764       0.000022   2.21   6000         NaN       NaN           NaN   \n",
       "16  0.0744       0.000020   2.40   6500         NaN       NaN           NaN   \n",
       "17  0.0752       0.000018   2.58   7000         NaN       NaN           NaN   \n",
       "18  0.0734       0.000015   2.76   7500         NaN       NaN           NaN   \n",
       "19  0.0754       0.000013   2.95   8000         NaN       NaN           NaN   \n",
       "20     NaN            NaN   3.00   8139    0.062667  0.700565      0.618275   \n",
       "21     NaN            NaN   3.00   8139         NaN       NaN           NaN   \n",
       "22  0.0677       0.000011   3.13   8500         NaN       NaN           NaN   \n",
       "23  0.0649       0.000009   3.32   9000         NaN       NaN           NaN   \n",
       "24  0.0645       0.000006   3.50   9500         NaN       NaN           NaN   \n",
       "25  0.0639       0.000004   3.69  10000         NaN       NaN           NaN   \n",
       "26  0.0645       0.000002   3.87  10500         NaN       NaN           NaN   \n",
       "27     NaN            NaN   4.00  10852    0.055359  0.748315      0.678005   \n",
       "28     NaN            NaN   4.00  10852         NaN       NaN           NaN   \n",
       "29     NaN            NaN   4.00  10852    0.084695       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "0               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "1               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "2               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "3               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "4               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "5          0.720449       0.727116        0.437707  ...        NaN       NaN   \n",
       "6               NaN            NaN             NaN  ...   0.090329  0.544464   \n",
       "7               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "8               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "9               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "10              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "11              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "12         0.767374       0.762475        0.496429  ...        NaN       NaN   \n",
       "13              NaN            NaN             NaN  ...   0.085440  0.561915   \n",
       "14              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "15              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "16              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "17              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "18              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "19              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "20         0.808124       0.805916        0.574318  ...        NaN       NaN   \n",
       "21              NaN            NaN             NaN  ...   0.085390  0.577114   \n",
       "22              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "23              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "24              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "25              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "26              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "27         0.834896       0.836060        0.631957  ...        NaN       NaN   \n",
       "28              NaN            NaN             NaN  ...   0.087316  0.578279   \n",
       "29              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "0           NaN             NaN           NaN            NaN           NaN   \n",
       "1           NaN             NaN           NaN            NaN           NaN   \n",
       "2           NaN             NaN           NaN            NaN           NaN   \n",
       "3           NaN             NaN           NaN            NaN           NaN   \n",
       "4           NaN             NaN           NaN            NaN           NaN   \n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "6      0.446238        0.698136      0.718890       0.427387       21.7372   \n",
       "7           NaN             NaN           NaN            NaN           NaN   \n",
       "8           NaN             NaN           NaN            NaN           NaN   \n",
       "9           NaN             NaN           NaN            NaN           NaN   \n",
       "10          NaN             NaN           NaN            NaN           NaN   \n",
       "11          NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "13     0.470846        0.696660      0.730930       0.437707       20.1700   \n",
       "14          NaN             NaN           NaN            NaN           NaN   \n",
       "15          NaN             NaN           NaN            NaN           NaN   \n",
       "16          NaN             NaN           NaN            NaN           NaN   \n",
       "17          NaN             NaN           NaN            NaN           NaN   \n",
       "18          NaN             NaN           NaN            NaN           NaN   \n",
       "19          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "21     0.502351        0.678020      0.745947       0.462403       21.0338   \n",
       "22          NaN             NaN           NaN            NaN           NaN   \n",
       "23          NaN             NaN           NaN            NaN           NaN   \n",
       "24          NaN             NaN           NaN            NaN           NaN   \n",
       "25          NaN             NaN           NaN            NaN           NaN   \n",
       "26          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "28     0.514107        0.660757      0.751268       0.467011      102.8424   \n",
       "29          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second    total_flos  \n",
       "0                       NaN                    NaN           NaN  \n",
       "1                       NaN                    NaN           NaN  \n",
       "2                       NaN                    NaN           NaN  \n",
       "3                       NaN                    NaN           NaN  \n",
       "4                       NaN                    NaN           NaN  \n",
       "5                       NaN                    NaN           NaN  \n",
       "6                   249.619                 15.641           NaN  \n",
       "7                       NaN                    NaN           NaN  \n",
       "8                       NaN                    NaN           NaN  \n",
       "9                       NaN                    NaN           NaN  \n",
       "10                      NaN                    NaN           NaN  \n",
       "11                      NaN                    NaN           NaN  \n",
       "12                      NaN                    NaN           NaN  \n",
       "13                  269.014                 16.857           NaN  \n",
       "14                      NaN                    NaN           NaN  \n",
       "15                      NaN                    NaN           NaN  \n",
       "16                      NaN                    NaN           NaN  \n",
       "17                      NaN                    NaN           NaN  \n",
       "18                      NaN                    NaN           NaN  \n",
       "19                      NaN                    NaN           NaN  \n",
       "20                      NaN                    NaN           NaN  \n",
       "21                  257.965                 16.164           NaN  \n",
       "22                      NaN                    NaN           NaN  \n",
       "23                      NaN                    NaN           NaN  \n",
       "24                      NaN                    NaN           NaN  \n",
       "25                      NaN                    NaN           NaN  \n",
       "26                      NaN                    NaN           NaN  \n",
       "27                      NaN                    NaN           NaN  \n",
       "28                   52.760                  3.306           NaN  \n",
       "29                      NaN                    NaN  1.856366e+16  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view train and validation metrics from training\n",
    "log_history = pd.DataFrame(trainer.state.log_history)\n",
    "log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf0d198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.563055</td>\n",
       "      <td>0.462101</td>\n",
       "      <td>0.720449</td>\n",
       "      <td>0.727116</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>0.628388</td>\n",
       "      <td>0.532027</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.618275</td>\n",
       "      <td>0.808124</td>\n",
       "      <td>0.805916</td>\n",
       "      <td>0.574318</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.748315</td>\n",
       "      <td>0.678005</td>\n",
       "      <td>0.834896</td>\n",
       "      <td>0.836060</td>\n",
       "      <td>0.631957</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "5    NaN            NaN    1.0   2713    0.086619  0.563055      0.462101   \n",
       "12   NaN            NaN    2.0   5426    0.073567  0.628388      0.532027   \n",
       "20   NaN            NaN    3.0   8139    0.062667  0.700565      0.618275   \n",
       "27   NaN            NaN    4.0  10852    0.055359  0.748315      0.678005   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss  eval_f1  \\\n",
       "5          0.720449       0.727116        0.437707  ...        NaN      NaN   \n",
       "12         0.767374       0.762475        0.496429  ...        NaN      NaN   \n",
       "20         0.808124       0.805916        0.574318  ...        NaN      NaN   \n",
       "27         0.834896       0.836060        0.631957  ...        NaN      NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "5                       NaN                    NaN         NaN  \n",
       "12                      NaN                    NaN         NaN  \n",
       "20                      NaN                    NaN         NaN  \n",
       "27                      NaN                    NaN         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store train metrics in dataframe\n",
    "train_history = log_history[log_history['train_f1'].notna()]\n",
    "train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97eea248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090329</td>\n",
       "      <td>0.544464</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.698136</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.427387</td>\n",
       "      <td>21.7372</td>\n",
       "      <td>249.619</td>\n",
       "      <td>15.641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085440</td>\n",
       "      <td>0.561915</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.696660</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>20.1700</td>\n",
       "      <td>269.014</td>\n",
       "      <td>16.857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085390</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.502351</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>0.462403</td>\n",
       "      <td>21.0338</td>\n",
       "      <td>257.965</td>\n",
       "      <td>16.164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.514107</td>\n",
       "      <td>0.660757</td>\n",
       "      <td>0.751268</td>\n",
       "      <td>0.467011</td>\n",
       "      <td>102.8424</td>\n",
       "      <td>52.760</td>\n",
       "      <td>3.306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "6    NaN            NaN    1.0   2713         NaN       NaN           NaN   \n",
       "13   NaN            NaN    2.0   5426         NaN       NaN           NaN   \n",
       "21   NaN            NaN    3.0   8139         NaN       NaN           NaN   \n",
       "28   NaN            NaN    4.0  10852         NaN       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "6               NaN            NaN             NaN  ...   0.090329  0.544464   \n",
       "13              NaN            NaN             NaN  ...   0.085440  0.561915   \n",
       "21              NaN            NaN             NaN  ...   0.085390  0.577114   \n",
       "28              NaN            NaN             NaN  ...   0.087316  0.578279   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "6      0.446238        0.698136      0.718890       0.427387       21.7372   \n",
       "13     0.470846        0.696660      0.730930       0.437707       20.1700   \n",
       "21     0.502351        0.678020      0.745947       0.462403       21.0338   \n",
       "28     0.514107        0.660757      0.751268       0.467011      102.8424   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "6                   249.619                 15.641         NaN  \n",
       "13                  269.014                 16.857         NaN  \n",
       "21                  257.965                 16.164         NaN  \n",
       "28                   52.760                  3.306         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store validation metrics in dataframe\n",
    "val_history = log_history[log_history['eval_f1'].notna()]\n",
    "val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "978bf0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_x</th>\n",
       "      <th>learning_rate_x</th>\n",
       "      <th>epoch_x</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_x</th>\n",
       "      <th>train_f1_x</th>\n",
       "      <th>train_recall_x</th>\n",
       "      <th>train_precision_x</th>\n",
       "      <th>train_roc_auc_x</th>\n",
       "      <th>train_accuracy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss_y</th>\n",
       "      <th>eval_f1_y</th>\n",
       "      <th>eval_recall_y</th>\n",
       "      <th>eval_precision_y</th>\n",
       "      <th>eval_roc_auc_y</th>\n",
       "      <th>eval_accuracy_y</th>\n",
       "      <th>eval_runtime_y</th>\n",
       "      <th>eval_samples_per_second_y</th>\n",
       "      <th>eval_steps_per_second_y</th>\n",
       "      <th>total_flos_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.563055</td>\n",
       "      <td>0.462101</td>\n",
       "      <td>0.720449</td>\n",
       "      <td>0.727116</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090329</td>\n",
       "      <td>0.544464</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.698136</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.427387</td>\n",
       "      <td>21.7372</td>\n",
       "      <td>249.619</td>\n",
       "      <td>15.641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>0.628388</td>\n",
       "      <td>0.532027</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085440</td>\n",
       "      <td>0.561915</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.696660</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>20.1700</td>\n",
       "      <td>269.014</td>\n",
       "      <td>16.857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.618275</td>\n",
       "      <td>0.808124</td>\n",
       "      <td>0.805916</td>\n",
       "      <td>0.574318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085390</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.502351</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>0.462403</td>\n",
       "      <td>21.0338</td>\n",
       "      <td>257.965</td>\n",
       "      <td>16.164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.748315</td>\n",
       "      <td>0.678005</td>\n",
       "      <td>0.834896</td>\n",
       "      <td>0.836060</td>\n",
       "      <td>0.631957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.514107</td>\n",
       "      <td>0.660757</td>\n",
       "      <td>0.751268</td>\n",
       "      <td>0.467011</td>\n",
       "      <td>102.8424</td>\n",
       "      <td>52.760</td>\n",
       "      <td>3.306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_x  learning_rate_x  epoch_x   step  train_loss_x  train_f1_x  \\\n",
       "0     NaN              NaN      1.0   2713      0.086619    0.563055   \n",
       "1     NaN              NaN      2.0   5426      0.073567    0.628388   \n",
       "2     NaN              NaN      3.0   8139      0.062667    0.700565   \n",
       "3     NaN              NaN      4.0  10852      0.055359    0.748315   \n",
       "\n",
       "   train_recall_x  train_precision_x  train_roc_auc_x  train_accuracy_x  ...  \\\n",
       "0        0.462101           0.720449         0.727116          0.437707  ...   \n",
       "1        0.532027           0.767374         0.762475          0.496429  ...   \n",
       "2        0.618275           0.808124         0.805916          0.574318  ...   \n",
       "3        0.678005           0.834896         0.836060          0.631957  ...   \n",
       "\n",
       "   eval_loss_y  eval_f1_y  eval_recall_y  eval_precision_y  eval_roc_auc_y  \\\n",
       "0     0.090329   0.544464       0.446238          0.698136        0.718890   \n",
       "1     0.085440   0.561915       0.470846          0.696660        0.730930   \n",
       "2     0.085390   0.577114       0.502351          0.678020        0.745947   \n",
       "3     0.087316   0.578279       0.514107          0.660757        0.751268   \n",
       "\n",
       "   eval_accuracy_y  eval_runtime_y  eval_samples_per_second_y  \\\n",
       "0         0.427387         21.7372                    249.619   \n",
       "1         0.437707         20.1700                    269.014   \n",
       "2         0.462403         21.0338                    257.965   \n",
       "3         0.467011        102.8424                     52.760   \n",
       "\n",
       "   eval_steps_per_second_y  total_flos_y  \n",
       "0                   15.641           NaN  \n",
       "1                   16.857           NaN  \n",
       "2                   16.164           NaN  \n",
       "3                    3.306           NaN  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.merge(train_history, val_history, on='step', how='outer')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ebe0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function to check for accuracy with graphs \n",
    "def plot_model_performance(history):\n",
    "\n",
    "    #getting train and validation accuracy\n",
    "    acc = history['train_accuracy_x']\n",
    "    val_acc = history['eval_accuracy_y']\n",
    "\n",
    "    #getting train and validation loss\n",
    "    loss = history['train_loss_x']\n",
    "    val_loss = history['eval_loss_y']\n",
    "\n",
    "    epochs_range = range(4)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c97c350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7fb89",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5456e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate the model on the test set\n",
    "def evaluate_model(test_dataset):\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7bb617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08563675731420517, 'eval_f1': 0.583362831858407, 'eval_recall': 0.5207773739927318, 'eval_precision': 0.6630456648561658, 'eval_roc_auc': 0.7546376930186007, 'eval_accuracy': 0.47687488483508383, 'eval_runtime': 81.1496, 'eval_samples_per_second': 66.877, 'eval_steps_per_second': 4.19, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c172305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78c37071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(trainer, test_dataset, target_cols):\n",
    "    y_test = trainer.predict(test_dataset)\n",
    "    threshold = 0.5\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(y_test.predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    \n",
    "    # finally, compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794fec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.583363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.520777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.663046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.754638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.476875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.583363\n",
       "recall     0.520777\n",
       "precision  0.663046\n",
       "roc_auc    0.754638\n",
       "accuracy   0.476875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.641</td>\n",
       "      <td>504</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.806</td>\n",
       "      <td>264</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.474</td>\n",
       "      <td>198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.297</td>\n",
       "      <td>320</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.376</td>\n",
       "      <td>351</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.385</td>\n",
       "      <td>135</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.437</td>\n",
       "      <td>153</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.416</td>\n",
       "      <td>284</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.496</td>\n",
       "      <td>83</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.326</td>\n",
       "      <td>151</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.365</td>\n",
       "      <td>267</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>123</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.579</td>\n",
       "      <td>37</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.430</td>\n",
       "      <td>103</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.675</td>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.916</td>\n",
       "      <td>352</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.595</td>\n",
       "      <td>161</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.790</td>\n",
       "      <td>238</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.346</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.553</td>\n",
       "      <td>186</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.176</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.272</td>\n",
       "      <td>145</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.579</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.567</td>\n",
       "      <td>156</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.540</td>\n",
       "      <td>141</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.496</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.938      0.663   0.687  0.674  0.641      504        0.5\n",
       "amusement          0.981      0.788   0.845  0.815  0.806      264        0.5\n",
       "anger              0.967      0.568   0.424  0.486  0.474      198        0.5\n",
       "annoyance          0.938      0.450   0.238  0.311  0.297      320        0.5\n",
       "approval           0.937      0.524   0.316  0.394  0.376      351        0.5\n",
       "caring             0.974      0.465   0.341  0.393  0.385      135        0.5\n",
       "confusion          0.973      0.527   0.386  0.445  0.437      153        0.5\n",
       "curiosity          0.944      0.465   0.426  0.445  0.416      284        0.5\n",
       "desire             0.987      0.635   0.398  0.489  0.496       83        0.5\n",
       "disappointment     0.974      0.650   0.172  0.272  0.326      151        0.5\n",
       "disapproval        0.948      0.463   0.330  0.385  0.365      267        0.5\n",
       "disgust            0.981      0.631   0.431  0.512  0.512      123        0.5\n",
       "embarrassment      0.995      0.833   0.405  0.545  0.579       37        0.5\n",
       "excitement         0.983      0.615   0.311  0.413  0.430      103        0.5\n",
       "fear               0.991      0.667   0.692  0.679  0.675       78        0.5\n",
       "gratitude          0.990      0.933   0.909  0.921  0.916      352        0.5\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.5\n",
       "joy                0.978      0.650   0.565  0.605  0.595      161        0.5\n",
       "love               0.982      0.773   0.828  0.799  0.790      238        0.5\n",
       "nervousness        0.996      0.556   0.217  0.312  0.346       23        0.5\n",
       "optimism           0.974      0.669   0.478  0.558  0.553      186        0.5\n",
       "pride              0.997      0.500   0.062  0.111  0.176       16        0.5\n",
       "realization        0.972      0.448   0.179  0.256  0.272      145        0.5\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.5\n",
       "remorse            0.990      0.529   0.643  0.581  0.579       56        0.5\n",
       "sadness            0.978      0.629   0.532  0.576  0.567      156        0.5\n",
       "surprise           0.978      0.595   0.511  0.550  0.540      141        0.5\n",
       "neutral            0.787      0.727   0.565  0.636  0.496     1787        0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, outputs = calc_test_metrics(trainer, test_dataset, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]          [love, remorse]\n",
      "1  [admiration]             [admiration]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]                       []\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(outputs[i])[0]) for i in range(len(outputs))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love, remorse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0       [love, remorse]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53492f7a",
   "metadata": {},
   "source": [
    "## 4. Save the output, tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('output_roberta_m2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./roberta_M2_transformer/')\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./roberta_M2_transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
