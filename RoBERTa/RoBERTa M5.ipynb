{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Roberta M5 (with BERT augmented data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "import copy\n",
    "from typing import Optional\n",
    "from torch import FloatTensor\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bd9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading bert augmented dataset into train dataset\n",
    "df_train = pd.read_csv('data/clean/augmented/augmented_insert_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46926bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Model Building# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af580be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43261378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffe4fe",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7c54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3d783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training set\n",
    "train_encodings = tokenizer(list(df_train['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],\n",
    "                                   'attention_mask': train_encodings['attention_mask'],\n",
    "                                   'labels': torch.tensor(df_train[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "# Tokenize the validation set\n",
    "val_encodings = tokenizer(list(df_val['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "valid_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],\n",
    "                                 'attention_mask': val_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_val[target_cols].values, dtype=torch.float32)})\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(list(df_test['clean_text']), padding=True, truncation=True, return_tensors='pt')\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],\n",
    "                                 'attention_mask': test_encodings['attention_mask'],\n",
    "                                 'labels': torch.tensor(df_test[target_cols].values, dtype=torch.float32)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4840",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0442a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download model from model hub\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(target_cols))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e91901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom callback to get train and validation info during training\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb5596",
   "metadata": {},
   "source": [
    "#### Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cdb39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "num_classes = len(target_cols)\n",
    "class_counts = np.sum(train_dataset['labels'], axis=0)\n",
    "class_weights = 1.0 / class_counts\n",
    "\n",
    "# Normalize weights\n",
    "class_weights /= class_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82eeccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00434095, 0.00770108, 0.01144105, 0.00725835, 0.00610007,\n",
       "       0.01649321, 0.01310535, 0.00818262, 0.02796899, 0.0141389 ,\n",
       "       0.00886653, 0.02260797, 0.05936463, 0.02101773, 0.03013129,\n",
       "       0.00673483, 0.23283272, 0.01234719, 0.0085945 , 0.10998846,\n",
       "       0.01133973, 0.16151459, 0.01615146, 0.11717725, 0.03289563,\n",
       "       0.01353066, 0.01691332, 0.00126095])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "611e9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom trainer to incorporate class weights\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights: Optional[FloatTensor] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            class_weights = class_weights.to(self.args.device)\n",
    "            logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
    "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        try:\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1,model.num_labels))\n",
    "        except AttributeError:  # DataParallel\n",
    "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1, model.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1980801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='data/output/',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_dir=\"data/output/logs\",\n",
    "    learning_rate=float(LEARNING_RATE),\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0eae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to calculate the metrics for multi label classification\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3287773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Trainer instance\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.add_callback(CustomCallback(trainer)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e1c6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishah/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10852' max='10852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10852/10852 1:26:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.407088</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>0.388454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.526532</td>\n",
       "      <td>0.421473</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.407298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.584005</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.452129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.087737</td>\n",
       "      <td>0.553390</td>\n",
       "      <td>0.456113</td>\n",
       "      <td>0.703408</td>\n",
       "      <td>0.723841</td>\n",
       "      <td>0.435127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.667045</td>\n",
       "      <td>0.574633</td>\n",
       "      <td>0.794878</td>\n",
       "      <td>0.784062</td>\n",
       "      <td>0.541052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.086056</td>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.491850</td>\n",
       "      <td>0.688158</td>\n",
       "      <td>0.741040</td>\n",
       "      <td>0.462956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.626299</td>\n",
       "      <td>0.820985</td>\n",
       "      <td>0.810153</td>\n",
       "      <td>0.590790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.087684</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.501411</td>\n",
       "      <td>0.671213</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>0.465536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10852, training_loss=0.0917661642615223, metrics={'train_runtime': 5212.7087, 'train_samples_per_second': 33.309, 'train_steps_per_second': 2.082, 'total_flos': 1.6243202655353856e+16, 'train_loss': 0.0917661642615223, 'epoch': 4.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dffa6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.18</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.407088</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>0.388454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.526532</td>\n",
       "      <td>0.421473</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.407298</td>\n",
       "      <td>21.3090</td>\n",
       "      <td>254.634</td>\n",
       "      <td>15.956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.584005</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.452129</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087737</td>\n",
       "      <td>0.553390</td>\n",
       "      <td>0.456113</td>\n",
       "      <td>0.703408</td>\n",
       "      <td>0.723841</td>\n",
       "      <td>0.435127</td>\n",
       "      <td>20.3355</td>\n",
       "      <td>266.825</td>\n",
       "      <td>16.720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.21</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.58</td>\n",
       "      <td>7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.76</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.95</td>\n",
       "      <td>8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.667045</td>\n",
       "      <td>0.574633</td>\n",
       "      <td>0.794878</td>\n",
       "      <td>0.784062</td>\n",
       "      <td>0.541052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086056</td>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.491850</td>\n",
       "      <td>0.688158</td>\n",
       "      <td>0.741040</td>\n",
       "      <td>0.462956</td>\n",
       "      <td>20.5140</td>\n",
       "      <td>264.503</td>\n",
       "      <td>16.574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.13</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.69</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.87</td>\n",
       "      <td>10500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.626299</td>\n",
       "      <td>0.820985</td>\n",
       "      <td>0.810153</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087684</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.501411</td>\n",
       "      <td>0.671213</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>0.465536</td>\n",
       "      <td>20.5684</td>\n",
       "      <td>263.803</td>\n",
       "      <td>16.530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.091766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624320e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "0   0.1567       0.000048   0.18    500         NaN       NaN           NaN   \n",
       "1   0.1239       0.000045   0.37   1000         NaN       NaN           NaN   \n",
       "2   0.1159       0.000043   0.55   1500         NaN       NaN           NaN   \n",
       "3   0.1078       0.000041   0.74   2000         NaN       NaN           NaN   \n",
       "4   0.1036       0.000038   0.92   2500         NaN       NaN           NaN   \n",
       "5      NaN            NaN   1.00   2713    0.094684  0.516686      0.407088   \n",
       "6      NaN            NaN   1.00   2713         NaN       NaN           NaN   \n",
       "7   0.0983       0.000036   1.11   3000         NaN       NaN           NaN   \n",
       "8   0.0963       0.000034   1.29   3500         NaN       NaN           NaN   \n",
       "9   0.0942       0.000032   1.47   4000         NaN       NaN           NaN   \n",
       "10  0.0918       0.000029   1.66   4500         NaN       NaN           NaN   \n",
       "11  0.0922       0.000027   1.84   5000         NaN       NaN           NaN   \n",
       "12     NaN            NaN   2.00   5426    0.080681  0.584005      0.476094   \n",
       "13     NaN            NaN   2.00   5426         NaN       NaN           NaN   \n",
       "14  0.0888       0.000025   2.03   5500         NaN       NaN           NaN   \n",
       "15  0.0834       0.000022   2.21   6000         NaN       NaN           NaN   \n",
       "16  0.0822       0.000020   2.40   6500         NaN       NaN           NaN   \n",
       "17  0.0819       0.000018   2.58   7000         NaN       NaN           NaN   \n",
       "18  0.0801       0.000015   2.76   7500         NaN       NaN           NaN   \n",
       "19  0.0827       0.000013   2.95   8000         NaN       NaN           NaN   \n",
       "20     NaN            NaN   3.00   8139    0.068802  0.667045      0.574633   \n",
       "21     NaN            NaN   3.00   8139         NaN       NaN           NaN   \n",
       "22  0.0751       0.000011   3.13   8500         NaN       NaN           NaN   \n",
       "23  0.0716       0.000009   3.32   9000         NaN       NaN           NaN   \n",
       "24  0.0719       0.000006   3.50   9500         NaN       NaN           NaN   \n",
       "25  0.0714       0.000004   3.69  10000         NaN       NaN           NaN   \n",
       "26  0.0713       0.000002   3.87  10500         NaN       NaN           NaN   \n",
       "27     NaN            NaN   4.00  10852    0.062258  0.710548      0.626299   \n",
       "28     NaN            NaN   4.00  10852         NaN       NaN           NaN   \n",
       "29     NaN            NaN   4.00  10852    0.091766       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "0               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "1               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "2               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "3               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "4               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "5          0.707036       0.699843        0.388454  ...        NaN       NaN   \n",
       "6               NaN            NaN             NaN  ...   0.094801  0.526532   \n",
       "7               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "8               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "9               NaN            NaN             NaN  ...        NaN       NaN   \n",
       "10              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "11              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "12         0.755169       0.734660        0.452129  ...        NaN       NaN   \n",
       "13              NaN            NaN             NaN  ...   0.087737  0.553390   \n",
       "14              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "15              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "16              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "17              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "18              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "19              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "20         0.794878       0.784062        0.541052  ...        NaN       NaN   \n",
       "21              NaN            NaN             NaN  ...   0.086056  0.573675   \n",
       "22              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "23              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "24              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "25              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "26              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "27         0.820985       0.810153        0.590790  ...        NaN       NaN   \n",
       "28              NaN            NaN             NaN  ...   0.087684  0.574018   \n",
       "29              NaN            NaN             NaN  ...        NaN       NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "0           NaN             NaN           NaN            NaN           NaN   \n",
       "1           NaN             NaN           NaN            NaN           NaN   \n",
       "2           NaN             NaN           NaN            NaN           NaN   \n",
       "3           NaN             NaN           NaN            NaN           NaN   \n",
       "4           NaN             NaN           NaN            NaN           NaN   \n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "6      0.421473        0.701356      0.706803       0.407298       21.3090   \n",
       "7           NaN             NaN           NaN            NaN           NaN   \n",
       "8           NaN             NaN           NaN            NaN           NaN   \n",
       "9           NaN             NaN           NaN            NaN           NaN   \n",
       "10          NaN             NaN           NaN            NaN           NaN   \n",
       "11          NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "13     0.456113        0.703408      0.723841       0.435127       20.3355   \n",
       "14          NaN             NaN           NaN            NaN           NaN   \n",
       "15          NaN             NaN           NaN            NaN           NaN   \n",
       "16          NaN             NaN           NaN            NaN           NaN   \n",
       "17          NaN             NaN           NaN            NaN           NaN   \n",
       "18          NaN             NaN           NaN            NaN           NaN   \n",
       "19          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "21     0.491850        0.688158      0.741040       0.462956       20.5140   \n",
       "22          NaN             NaN           NaN            NaN           NaN   \n",
       "23          NaN             NaN           NaN            NaN           NaN   \n",
       "24          NaN             NaN           NaN            NaN           NaN   \n",
       "25          NaN             NaN           NaN            NaN           NaN   \n",
       "26          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "28     0.501411        0.671213      0.745322       0.465536       20.5684   \n",
       "29          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second    total_flos  \n",
       "0                       NaN                    NaN           NaN  \n",
       "1                       NaN                    NaN           NaN  \n",
       "2                       NaN                    NaN           NaN  \n",
       "3                       NaN                    NaN           NaN  \n",
       "4                       NaN                    NaN           NaN  \n",
       "5                       NaN                    NaN           NaN  \n",
       "6                   254.634                 15.956           NaN  \n",
       "7                       NaN                    NaN           NaN  \n",
       "8                       NaN                    NaN           NaN  \n",
       "9                       NaN                    NaN           NaN  \n",
       "10                      NaN                    NaN           NaN  \n",
       "11                      NaN                    NaN           NaN  \n",
       "12                      NaN                    NaN           NaN  \n",
       "13                  266.825                 16.720           NaN  \n",
       "14                      NaN                    NaN           NaN  \n",
       "15                      NaN                    NaN           NaN  \n",
       "16                      NaN                    NaN           NaN  \n",
       "17                      NaN                    NaN           NaN  \n",
       "18                      NaN                    NaN           NaN  \n",
       "19                      NaN                    NaN           NaN  \n",
       "20                      NaN                    NaN           NaN  \n",
       "21                  264.503                 16.574           NaN  \n",
       "22                      NaN                    NaN           NaN  \n",
       "23                      NaN                    NaN           NaN  \n",
       "24                      NaN                    NaN           NaN  \n",
       "25                      NaN                    NaN           NaN  \n",
       "26                      NaN                    NaN           NaN  \n",
       "27                      NaN                    NaN           NaN  \n",
       "28                  263.803                 16.530           NaN  \n",
       "29                      NaN                    NaN  1.624320e+16  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view train and validation metrics from training\n",
    "log_history = pd.DataFrame(trainer.state.log_history)\n",
    "log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf0d198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.407088</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>0.388454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.584005</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.452129</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.667045</td>\n",
       "      <td>0.574633</td>\n",
       "      <td>0.794878</td>\n",
       "      <td>0.784062</td>\n",
       "      <td>0.541052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.626299</td>\n",
       "      <td>0.820985</td>\n",
       "      <td>0.810153</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "5    NaN            NaN    1.0   2713    0.094684  0.516686      0.407088   \n",
       "12   NaN            NaN    2.0   5426    0.080681  0.584005      0.476094   \n",
       "20   NaN            NaN    3.0   8139    0.068802  0.667045      0.574633   \n",
       "27   NaN            NaN    4.0  10852    0.062258  0.710548      0.626299   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss  eval_f1  \\\n",
       "5          0.707036       0.699843        0.388454  ...        NaN      NaN   \n",
       "12         0.755169       0.734660        0.452129  ...        NaN      NaN   \n",
       "20         0.794878       0.784062        0.541052  ...        NaN      NaN   \n",
       "27         0.820985       0.810153        0.590790  ...        NaN      NaN   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "5           NaN             NaN           NaN            NaN           NaN   \n",
       "12          NaN             NaN           NaN            NaN           NaN   \n",
       "20          NaN             NaN           NaN            NaN           NaN   \n",
       "27          NaN             NaN           NaN            NaN           NaN   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "5                       NaN                    NaN         NaN  \n",
       "12                      NaN                    NaN         NaN  \n",
       "20                      NaN                    NaN         NaN  \n",
       "27                      NaN                    NaN         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store train metrics in dataframe\n",
    "train_history = log_history[log_history['train_f1'].notna()]\n",
    "train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97eea248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.526532</td>\n",
       "      <td>0.421473</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.407298</td>\n",
       "      <td>21.3090</td>\n",
       "      <td>254.634</td>\n",
       "      <td>15.956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087737</td>\n",
       "      <td>0.553390</td>\n",
       "      <td>0.456113</td>\n",
       "      <td>0.703408</td>\n",
       "      <td>0.723841</td>\n",
       "      <td>0.435127</td>\n",
       "      <td>20.3355</td>\n",
       "      <td>266.825</td>\n",
       "      <td>16.720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086056</td>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.491850</td>\n",
       "      <td>0.688158</td>\n",
       "      <td>0.741040</td>\n",
       "      <td>0.462956</td>\n",
       "      <td>20.5140</td>\n",
       "      <td>264.503</td>\n",
       "      <td>16.574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087684</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.501411</td>\n",
       "      <td>0.671213</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>0.465536</td>\n",
       "      <td>20.5684</td>\n",
       "      <td>263.803</td>\n",
       "      <td>16.530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  learning_rate  epoch   step  train_loss  train_f1  train_recall  \\\n",
       "6    NaN            NaN    1.0   2713         NaN       NaN           NaN   \n",
       "13   NaN            NaN    2.0   5426         NaN       NaN           NaN   \n",
       "21   NaN            NaN    3.0   8139         NaN       NaN           NaN   \n",
       "28   NaN            NaN    4.0  10852         NaN       NaN           NaN   \n",
       "\n",
       "    train_precision  train_roc_auc  train_accuracy  ...  eval_loss   eval_f1  \\\n",
       "6               NaN            NaN             NaN  ...   0.094801  0.526532   \n",
       "13              NaN            NaN             NaN  ...   0.087737  0.553390   \n",
       "21              NaN            NaN             NaN  ...   0.086056  0.573675   \n",
       "28              NaN            NaN             NaN  ...   0.087684  0.574018   \n",
       "\n",
       "    eval_recall  eval_precision  eval_roc_auc  eval_accuracy  eval_runtime  \\\n",
       "6      0.421473        0.701356      0.706803       0.407298       21.3090   \n",
       "13     0.456113        0.703408      0.723841       0.435127       20.3355   \n",
       "21     0.491850        0.688158      0.741040       0.462956       20.5140   \n",
       "28     0.501411        0.671213      0.745322       0.465536       20.5684   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  total_flos  \n",
       "6                   254.634                 15.956         NaN  \n",
       "13                  266.825                 16.720         NaN  \n",
       "21                  264.503                 16.574         NaN  \n",
       "28                  263.803                 16.530         NaN  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store validation metrics in dataframe\n",
    "val_history = log_history[log_history['eval_f1'].notna()]\n",
    "val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "978bf0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_x</th>\n",
       "      <th>learning_rate_x</th>\n",
       "      <th>epoch_x</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_x</th>\n",
       "      <th>train_f1_x</th>\n",
       "      <th>train_recall_x</th>\n",
       "      <th>train_precision_x</th>\n",
       "      <th>train_roc_auc_x</th>\n",
       "      <th>train_accuracy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_loss_y</th>\n",
       "      <th>eval_f1_y</th>\n",
       "      <th>eval_recall_y</th>\n",
       "      <th>eval_precision_y</th>\n",
       "      <th>eval_roc_auc_y</th>\n",
       "      <th>eval_accuracy_y</th>\n",
       "      <th>eval_runtime_y</th>\n",
       "      <th>eval_samples_per_second_y</th>\n",
       "      <th>eval_steps_per_second_y</th>\n",
       "      <th>total_flos_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2713</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.516686</td>\n",
       "      <td>0.407088</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>0.388454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.526532</td>\n",
       "      <td>0.421473</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.407298</td>\n",
       "      <td>21.3090</td>\n",
       "      <td>254.634</td>\n",
       "      <td>15.956</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.584005</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.452129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087737</td>\n",
       "      <td>0.553390</td>\n",
       "      <td>0.456113</td>\n",
       "      <td>0.703408</td>\n",
       "      <td>0.723841</td>\n",
       "      <td>0.435127</td>\n",
       "      <td>20.3355</td>\n",
       "      <td>266.825</td>\n",
       "      <td>16.720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.667045</td>\n",
       "      <td>0.574633</td>\n",
       "      <td>0.794878</td>\n",
       "      <td>0.784062</td>\n",
       "      <td>0.541052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086056</td>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.491850</td>\n",
       "      <td>0.688158</td>\n",
       "      <td>0.741040</td>\n",
       "      <td>0.462956</td>\n",
       "      <td>20.5140</td>\n",
       "      <td>264.503</td>\n",
       "      <td>16.574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10852</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.626299</td>\n",
       "      <td>0.820985</td>\n",
       "      <td>0.810153</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087684</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.501411</td>\n",
       "      <td>0.671213</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>0.465536</td>\n",
       "      <td>20.5684</td>\n",
       "      <td>263.803</td>\n",
       "      <td>16.530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_x  learning_rate_x  epoch_x   step  train_loss_x  train_f1_x  \\\n",
       "0     NaN              NaN      1.0   2713      0.094684    0.516686   \n",
       "1     NaN              NaN      2.0   5426      0.080681    0.584005   \n",
       "2     NaN              NaN      3.0   8139      0.068802    0.667045   \n",
       "3     NaN              NaN      4.0  10852      0.062258    0.710548   \n",
       "\n",
       "   train_recall_x  train_precision_x  train_roc_auc_x  train_accuracy_x  ...  \\\n",
       "0        0.407088           0.707036         0.699843          0.388454  ...   \n",
       "1        0.476094           0.755169         0.734660          0.452129  ...   \n",
       "2        0.574633           0.794878         0.784062          0.541052  ...   \n",
       "3        0.626299           0.820985         0.810153          0.590790  ...   \n",
       "\n",
       "   eval_loss_y  eval_f1_y  eval_recall_y  eval_precision_y  eval_roc_auc_y  \\\n",
       "0     0.094801   0.526532       0.421473          0.701356        0.706803   \n",
       "1     0.087737   0.553390       0.456113          0.703408        0.723841   \n",
       "2     0.086056   0.573675       0.491850          0.688158        0.741040   \n",
       "3     0.087684   0.574018       0.501411          0.671213        0.745322   \n",
       "\n",
       "   eval_accuracy_y  eval_runtime_y  eval_samples_per_second_y  \\\n",
       "0         0.407298         21.3090                    254.634   \n",
       "1         0.435127         20.3355                    266.825   \n",
       "2         0.462956         20.5140                    264.503   \n",
       "3         0.465536         20.5684                    263.803   \n",
       "\n",
       "   eval_steps_per_second_y  total_flos_y  \n",
       "0                   15.956           NaN  \n",
       "1                   16.720           NaN  \n",
       "2                   16.574           NaN  \n",
       "3                   16.530           NaN  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.merge(train_history, val_history, on='step', how='outer')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebe0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function to check for accuracy with graphs \n",
    "def plot_model_performance(history):\n",
    "\n",
    "    #getting train and validation accuracy\n",
    "    acc = history['train_accuracy_x']\n",
    "    val_acc = history['eval_accuracy_y']\n",
    "\n",
    "    #getting train and validation loss\n",
    "    loss = history['train_loss_x']\n",
    "    val_loss = history['eval_loss_y']\n",
    "\n",
    "    epochs_range = range(4)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c97c350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7fb89",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5456e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate the model on the test set\n",
    "def evaluate_model(test_dataset):\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7bb617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08663992583751678, 'eval_f1': 0.5737275110749479, 'eval_recall': 0.5013430241744351, 'eval_precision': 0.6705409974640744, 'eval_roc_auc': 0.7453187959013455, 'eval_accuracy': 0.466740372213009, 'eval_runtime': 16.248, 'eval_samples_per_second': 334.01, 'eval_steps_per_second': 20.926, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c172305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c37071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(trainer, test_dataset, target_cols):\n",
    "    y_test = trainer.predict(test_dataset)\n",
    "    threshold = 0.5\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(y_test.predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    \n",
    "    # finally, compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "794fec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.573728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.670541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.745319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.466740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.573728\n",
       "recall     0.501343\n",
       "precision  0.670541\n",
       "roc_auc    0.745319\n",
       "accuracy   0.466740"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.646</td>\n",
       "      <td>504</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.803</td>\n",
       "      <td>264</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.416</td>\n",
       "      <td>198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.214</td>\n",
       "      <td>320</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.370</td>\n",
       "      <td>351</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.378</td>\n",
       "      <td>135</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.437</td>\n",
       "      <td>153</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.401</td>\n",
       "      <td>284</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.542</td>\n",
       "      <td>83</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.285</td>\n",
       "      <td>151</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.316</td>\n",
       "      <td>267</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.502</td>\n",
       "      <td>123</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.502</td>\n",
       "      <td>37</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.380</td>\n",
       "      <td>103</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.714</td>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.912</td>\n",
       "      <td>352</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.555</td>\n",
       "      <td>161</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.809</td>\n",
       "      <td>238</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.207</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.558</td>\n",
       "      <td>186</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.253</td>\n",
       "      <td>145</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.605</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.539</td>\n",
       "      <td>156</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.511</td>\n",
       "      <td>141</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.482</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.942      0.694   0.663  0.678  0.646      504        0.5\n",
       "amusement          0.980      0.759   0.871  0.811  0.803      264        0.5\n",
       "anger              0.964      0.518   0.364  0.427  0.416      198        0.5\n",
       "annoyance          0.938      0.426   0.134  0.204  0.214      320        0.5\n",
       "approval           0.940      0.575   0.274  0.371  0.370      351        0.5\n",
       "caring             0.974      0.478   0.319  0.382  0.378      135        0.5\n",
       "confusion          0.974      0.561   0.359  0.438  0.437      153        0.5\n",
       "curiosity          0.949      0.513   0.356  0.420  0.401      284        0.5\n",
       "desire             0.988      0.673   0.446  0.536  0.542       83        0.5\n",
       "disappointment     0.974      0.618   0.139  0.227  0.285      151        0.5\n",
       "disapproval        0.946      0.425   0.277  0.336  0.316      267        0.5\n",
       "disgust            0.981      0.630   0.415  0.500  0.502      123        0.5\n",
       "embarrassment      0.995      0.722   0.351  0.473  0.502       37        0.5\n",
       "excitement         0.981      0.517   0.291  0.373  0.380      103        0.5\n",
       "fear               0.992      0.718   0.718  0.718  0.714       78        0.5\n",
       "gratitude          0.989      0.938   0.898  0.917  0.912      352        0.5\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.5\n",
       "joy                0.977      0.645   0.497  0.561  0.555      161        0.5\n",
       "love               0.983      0.791   0.845  0.817  0.809      238        0.5\n",
       "nervousness        0.996      0.500   0.087  0.148  0.207       23        0.5\n",
       "optimism           0.974      0.679   0.478  0.562  0.558      186        0.5\n",
       "pride              0.997      0.000   0.000  0.000  0.000       16        0.5\n",
       "realization        0.973      0.477   0.145  0.222  0.253      145        0.5\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.5\n",
       "remorse            0.992      0.593   0.625  0.609  0.605       56        0.5\n",
       "sadness            0.978      0.655   0.462  0.541  0.539      156        0.5\n",
       "surprise           0.977      0.567   0.482  0.521  0.511      141        0.5\n",
       "neutral            0.780      0.700   0.578  0.633  0.482     1787        0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, outputs = calc_test_metrics(trainer, test_dataset, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]                   [love]\n",
      "1  [admiration]    [admiration, disgust]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]       [remorse, sadness]\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(outputs[i])[0]) for i in range(len(outputs))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, disgust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "                  Predicted  \n",
       "0                    [love]  \n",
       "1     [admiration, disgust]  \n",
       "2                [optimism]  \n",
       "3               [gratitude]  \n",
       "4                 [neutral]  \n",
       "...                     ...  \n",
       "5422            [gratitude]  \n",
       "5423                     []  \n",
       "5424              [neutral]  \n",
       "5425                  [joy]  \n",
       "5426              [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53492f7a",
   "metadata": {},
   "source": [
    "## 4. Save the output, tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('output_roberta_m5.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./roberta_M5_transformer/')\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('./roberta_M5_transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
