{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Ensemble M3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdb5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble M1\n",
    "\n",
    "Importing the necessary librariesimport os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. Loading the datafolder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9cab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c947014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path to load tokenizer and model\n",
    "roberta_pth = \"./roberta_M2_transformer/\"\n",
    "distilbert_pth = \"./distilbert_M2_transformer/\"\n",
    "distilbert_pth_2 = \"./distilbert_M4_transformer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e03551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_pth)\n",
    "\n",
    "# Load the model\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fd6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(distilbert_pth)\n",
    "\n",
    "# Load the model\n",
    "distilbert_model = AutoModelForSequenceClassification.from_pretrained(distilbert_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbef16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "distilbert_tokenizer_2 = AutoTokenizer.from_pretrained(distilbert_pth_2)\n",
    "\n",
    "# Load the model\n",
    "distilbert_model_2 = AutoModelForSequenceClassification.from_pretrained(distilbert_pth_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d2c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(y_test, target_cols):\n",
    "    threshold = 0.6\n",
    "    # compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the model and tokenizer in array\n",
    "models = [roberta_model, distilbert_model, distilbert_model_2]\n",
    "tokenizers = [roberta_tokenizer, distilbert_tokenizer, distilbert_tokenizer_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0feb482",
   "metadata": {},
   "source": [
    "## 3. Ensemble Fuzzy Integral Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genarate weight for models\n",
    "def generate_cardinality(N, p = 2):\n",
    "    return [(x/ N)**p for x in np.arange(N, 0, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8cd01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the prediction for each model and keep pred above the threshold value\n",
    "def fuzzy_integral_generalized(X, measure, axis = 0, f1 = np.minimum, f2 = np.amax, keepdims=True):\n",
    "    X_sorted = np.sort(X, axis = axis)\n",
    "    return f2(f1(np.take(X_sorted, np.arange(0, X_sorted.shape[axis]), axis), measure), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def predict(ensemble_prob):\n",
    "    predictions = np.zeros_like(ensemble_prob)\n",
    "    \n",
    "    for i in range(ensemble_prob.shape[0]):\n",
    "        temp = ensemble_prob[i]\n",
    "        # Thresholding: If value is greater than threshold, substitute with 1, else 0\n",
    "        predictions[i] = (temp >= 0.6).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7fee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load each model tokenizer, feed data into the model for prediction\n",
    "#Apply the fuzzy integral logic\n",
    "#Make predictions\n",
    "def my_ensemble(models, tokenizers, target_cols, df, y_true):\n",
    "    \n",
    "    count = 0\n",
    "    for model, tokenizer in zip(models, tokenizers):\n",
    "        count = count + 1\n",
    "        inputs = tokenizer(list(df['clean_text']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(torch.Tensor(outputs.logits))\n",
    "        probs_np = probs.cpu().detach().numpy()\n",
    "        \n",
    "        if count == 1: \n",
    "            prob1 = probs_np\n",
    "        elif count == 2 :\n",
    "            prob2 = probs_np\n",
    "        else: \n",
    "            prob3 = probs_np\n",
    "        \n",
    "    num_classes = prob1.shape[1] #Get number of labels\n",
    "    Y = np.zeros(prob1.shape,dtype=float) #create a mask with 0s\n",
    "    \n",
    "    for samples in range(prob1.shape[0]): #loops the rows in the test set\n",
    "        for classes in range(prob1.shape[1]): #loop the classes\n",
    "            X = np.array([prob1[samples][classes], prob2[samples][classes],  prob3[samples][classes]])\n",
    "            measure = [0.5, 1.5, 1.8]\n",
    "            X_agg = fuzzy_integral_generalized(X,measure)\n",
    "            Y[samples][classes] = X_agg\n",
    "    \n",
    "    y_predictions = predict(Y)    \n",
    "    \n",
    "    correct = np.where(y_predictions == y_true)[0].shape[0]\n",
    "    total = y_true.shape[0]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predictions)\n",
    "    print(\"Accuracy = \",accuracy)\n",
    "\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de001dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.4695043302008476\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_ensemble(models, tokenizers, target_cols, df_test, df_test[target_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a20ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.597728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.557118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.644725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.771888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.469504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.597728\n",
       "recall     0.557118\n",
       "precision  0.644725\n",
       "roc_auc    0.771888\n",
       "accuracy   0.469504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.659</td>\n",
       "      <td>504</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.823</td>\n",
       "      <td>264</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.500</td>\n",
       "      <td>198</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.306</td>\n",
       "      <td>320</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.396</td>\n",
       "      <td>351</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.401</td>\n",
       "      <td>135</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.457</td>\n",
       "      <td>153</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.369</td>\n",
       "      <td>284</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.491</td>\n",
       "      <td>83</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.330</td>\n",
       "      <td>151</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.393</td>\n",
       "      <td>267</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.533</td>\n",
       "      <td>123</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.540</td>\n",
       "      <td>37</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.384</td>\n",
       "      <td>103</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.675</td>\n",
       "      <td>78</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.916</td>\n",
       "      <td>352</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.586</td>\n",
       "      <td>161</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.789</td>\n",
       "      <td>238</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.314</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.572</td>\n",
       "      <td>186</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.374</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.286</td>\n",
       "      <td>145</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.699</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.570</td>\n",
       "      <td>156</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.507</td>\n",
       "      <td>141</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.504</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.938      0.641   0.750  0.691  0.659      504        0.6\n",
       "amusement          0.982      0.774   0.894  0.830  0.823      264        0.6\n",
       "anger              0.965      0.520   0.515  0.518  0.500      198        0.6\n",
       "annoyance          0.940      0.487   0.228  0.311  0.306      320        0.6\n",
       "approval           0.937      0.521   0.350  0.419  0.396      351        0.6\n",
       "caring             0.974      0.471   0.363  0.410  0.401      135        0.6\n",
       "confusion          0.972      0.508   0.438  0.470  0.457      153        0.6\n",
       "curiosity          0.943      0.447   0.356  0.396  0.369      284        0.6\n",
       "desire             0.987      0.623   0.398  0.485  0.491       83        0.6\n",
       "disappointment     0.974      0.622   0.185  0.286  0.330      151        0.6\n",
       "disapproval        0.945      0.436   0.408  0.422  0.393      267        0.6\n",
       "disgust            0.982      0.679   0.431  0.527  0.533      123        0.6\n",
       "embarrassment      0.995      0.778   0.378  0.509  0.540       37        0.6\n",
       "excitement         0.982      0.547   0.282  0.372  0.384      103        0.6\n",
       "fear               0.990      0.655   0.705  0.679  0.675       78        0.6\n",
       "gratitude          0.990      0.928   0.915  0.921  0.916      352        0.6\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.6\n",
       "joy                0.978      0.638   0.559  0.596  0.586      161        0.6\n",
       "love               0.981      0.751   0.849  0.797  0.789      238        0.6\n",
       "nervousness        0.996      0.571   0.174  0.267  0.314       23        0.6\n",
       "optimism           0.975      0.684   0.500  0.578  0.572      186        0.6\n",
       "pride              0.997      0.750   0.188  0.300  0.374       16        0.6\n",
       "realization        0.973      0.510   0.172  0.258  0.286      145        0.6\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.6\n",
       "remorse            0.993      0.629   0.786  0.698  0.699       56        0.6\n",
       "sadness            0.978      0.627   0.538  0.579  0.570      156        0.6\n",
       "surprise           0.975      0.529   0.511  0.520  0.507      141        0.6\n",
       "neutral            0.785      0.687   0.636  0.660  0.504     1787        0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, predictions = calc_test_metrics(y_pred, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]          [love, remorse]\n",
      "1  [admiration]             [admiration]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]                [remorse]\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(predictions[i])[0]) for i in range(len(predictions))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love, remorse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0       [love, remorse]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to csv\n",
    "result_df.to_csv('output_ensemble_3.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
