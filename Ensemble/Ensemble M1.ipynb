{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Ensemble M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.speci# Roberta M4 (with class weight)\n",
    "\n",
    "Importing the necessary librariesal import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. Loading the datafolder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9cab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c947014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path to load tokenizer and model\n",
    "roberta_pth = \"./roberta_M2_transformer/\"\n",
    "distilbert_pth = \"./distilbert_M2_transformer/\"\n",
    "roberta_m4_path = \"./roberta_M4_transformer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e03551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Roberta tokenizer\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_pth)\n",
    "\n",
    "# Load the Roberta model\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fd6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(distilbert_pth)\n",
    "\n",
    "# Load the model\n",
    "distilbert_model = AutoModelForSequenceClassification.from_pretrained(distilbert_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbef16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "roberta_tokenizer_2 = AutoTokenizer.from_pretrained(roberta_m4_path)\n",
    "\n",
    "# Load the model\n",
    "roberta_model_2 = AutoModelForSequenceClassification.from_pretrained(roberta_m4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d2c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(y_test, target_cols):\n",
    "    threshold = 0.6\n",
    "    # compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the model and tokenizer in array\n",
    "models = [roberta_model, distilbert_model, roberta_model_2]\n",
    "tokenizers = [roberta_tokenizer, distilbert_tokenizer, roberta_tokenizer_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cde9a4",
   "metadata": {},
   "source": [
    "## 3. Ensemble Fuzzy Integral Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genarate weight for models\n",
    "def generate_cardinality(N, p = 2):\n",
    "    return [(x/ N)**p for x in np.arange(N, 0, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8cd01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the prediction for each model and keep pred above the threshold value\n",
    "def fuzzy_integral_generalized(X, measure, axis = 0, f1 = np.minimum, f2 = np.amax, keepdims=True):\n",
    "    X_sorted = np.sort(X, axis = axis)\n",
    "    return f2(f1(np.take(X_sorted, np.arange(0, X_sorted.shape[axis]), axis), measure), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def predict(ensemble_prob):\n",
    "    predictions = np.zeros_like(ensemble_prob)\n",
    "    \n",
    "    for i in range(ensemble_prob.shape[0]):\n",
    "        temp = ensemble_prob[i]\n",
    "        # Thresholding: If value is greater than threshold, substitute with 1, else 0\n",
    "        predictions[i] = (temp >= 0.6).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7fee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load each model tokenizer, feed data into the model for prediction\n",
    "#Apply the fuzzy integral logic\n",
    "#Make predictions\n",
    "def my_ensemble(models, tokenizers, target_cols, df, y_true):\n",
    "    \n",
    "    count = 0\n",
    "    for model, tokenizer in zip(models, tokenizers):\n",
    "        count = count + 1\n",
    "        inputs = tokenizer(list(df['clean_text']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(torch.Tensor(outputs.logits))\n",
    "        probs_np = probs.cpu().detach().numpy()\n",
    "        \n",
    "        if count == 1: \n",
    "            prob1 = probs_np\n",
    "        elif count == 2 :\n",
    "            prob2 = probs_np\n",
    "        else: \n",
    "            prob3 = probs_np\n",
    "        \n",
    "    num_classes = prob1.shape[1] #Get number of labels\n",
    "    Y = np.zeros(prob1.shape,dtype=float) #create a mask with 0s\n",
    "    \n",
    "    for samples in range(prob1.shape[0]): #loops the rows in the test set\n",
    "        for classes in range(prob1.shape[1]): #loop the classes\n",
    "            X = np.array([prob1[samples][classes], prob2[samples][classes],  prob3[samples][classes]])\n",
    "            measure = [0.5, 1.5, 1.8]\n",
    "            X_agg = fuzzy_integral_generalized(X,measure)\n",
    "            Y[samples][classes] = X_agg\n",
    "    \n",
    "    y_predictions = predict(Y)    \n",
    "    \n",
    "    correct = np.where(y_predictions == y_true)[0].shape[0]\n",
    "    total = y_true.shape[0]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predictions)\n",
    "    print(\"Accuracy = \",accuracy)\n",
    "\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de001dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.4790860512253547\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_ensemble(models, tokenizers, target_cols, df_test, df_test[target_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a20ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.600494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.556802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.651627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.771932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.479086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.600494\n",
       "recall     0.556802\n",
       "precision  0.651627\n",
       "roc_auc    0.771932\n",
       "accuracy   0.479086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.673</td>\n",
       "      <td>504</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.818</td>\n",
       "      <td>264</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.492</td>\n",
       "      <td>198</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.294</td>\n",
       "      <td>320</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.401</td>\n",
       "      <td>351</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.403</td>\n",
       "      <td>135</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.447</td>\n",
       "      <td>153</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.364</td>\n",
       "      <td>284</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.496</td>\n",
       "      <td>83</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.323</td>\n",
       "      <td>151</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.392</td>\n",
       "      <td>267</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.509</td>\n",
       "      <td>123</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.536</td>\n",
       "      <td>37</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.387</td>\n",
       "      <td>103</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.691</td>\n",
       "      <td>78</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.920</td>\n",
       "      <td>352</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.584</td>\n",
       "      <td>161</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.792</td>\n",
       "      <td>238</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.314</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.559</td>\n",
       "      <td>186</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.288</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.277</td>\n",
       "      <td>145</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.689</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.586</td>\n",
       "      <td>156</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.541</td>\n",
       "      <td>141</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.517</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.940      0.653   0.762  0.703  0.673      504        0.6\n",
       "amusement          0.982      0.766   0.894  0.825  0.818      264        0.6\n",
       "anger              0.966      0.536   0.485  0.509  0.492      198        0.6\n",
       "annoyance          0.939      0.467   0.222  0.301  0.294      320        0.6\n",
       "approval           0.939      0.543   0.342  0.420  0.401      351        0.6\n",
       "caring             0.975      0.495   0.348  0.409  0.403      135        0.6\n",
       "confusion          0.972      0.508   0.418  0.459  0.447      153        0.6\n",
       "curiosity          0.943      0.441   0.352  0.391  0.364      284        0.6\n",
       "desire             0.987      0.635   0.398  0.489  0.496       83        0.6\n",
       "disappointment     0.974      0.596   0.185  0.283  0.323      151        0.6\n",
       "disapproval        0.945      0.440   0.401  0.420  0.392      267        0.6\n",
       "disgust            0.981      0.634   0.423  0.507  0.509      123        0.6\n",
       "embarrassment      0.995      0.714   0.405  0.517  0.536       37        0.6\n",
       "excitement         0.982      0.536   0.291  0.377  0.387      103        0.6\n",
       "fear               0.991      0.675   0.718  0.696  0.691       78        0.6\n",
       "gratitude          0.990      0.934   0.918  0.926  0.920      352        0.6\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.6\n",
       "joy                0.977      0.634   0.559  0.594  0.584      161        0.6\n",
       "love               0.981      0.750   0.857  0.800  0.792      238        0.6\n",
       "nervousness        0.996      0.571   0.174  0.267  0.314       23        0.6\n",
       "optimism           0.974      0.648   0.505  0.568  0.559      186        0.6\n",
       "pride              0.997      0.667   0.125  0.211  0.288       16        0.6\n",
       "realization        0.973      0.464   0.179  0.259  0.277      145        0.6\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.6\n",
       "remorse            0.993      0.611   0.786  0.688  0.689       56        0.6\n",
       "sadness            0.979      0.654   0.545  0.594  0.586      156        0.6\n",
       "surprise           0.977      0.567   0.539  0.553  0.541      141        0.6\n",
       "neutral            0.791      0.701   0.636  0.667  0.517     1787        0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, predictions = calc_test_metrics(y_pred, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]          [love, remorse]\n",
      "1  [admiration]             [admiration]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]                [remorse]\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(predictions[i])[0]) for i in range(len(predictions))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love, remorse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0       [love, remorse]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to csv\n",
    "result_df.to_csv('output_ensemble_1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
