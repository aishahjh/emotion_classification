{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4b07d",
   "metadata": {},
   "source": [
    "# Ensemble M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c3d39",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdb5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import nltk.corpus\n",
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer,TrainerCallback\n",
    "import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction   \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8380697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30b595",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9fc1af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. Loading the datafolder_path = 'data/clean/'\n",
    "file_pattern = folder_path + '*.csv'\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if 'train' in csv_file:\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "    elif 'val' in csv_file:\n",
    "        df_val = pd.read_csv(csv_file)\n",
    "    else:\n",
    "        df_test = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87038cff",
   "metadata": {},
   "source": [
    "#### Storing all 28 labels into variable target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9cab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_train.columns if col not in ['clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbe2a",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c947014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path to load tokenizer and model\n",
    "roberta_pth = \"./roberta_M2_transformer/\"\n",
    "distilbert_pth = \"./distilbert_M2_transformer/\"\n",
    "roberta_m5_path = \"./roberta_M5_transformer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e03551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_pth)\n",
    "\n",
    "# Load the model\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fd6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(distilbert_pth)\n",
    "\n",
    "# Load the model\n",
    "distilbert_model = AutoModelForSequenceClassification.from_pretrained(distilbert_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbef16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "roberta_tokenizer_2 = AutoTokenizer.from_pretrained(roberta_m5_path)\n",
    "\n",
    "# Load the model\n",
    "roberta_model_2 = AutoModelForSequenceClassification.from_pretrained(roberta_m5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate each emotion label metrics on test set\n",
    "def calc_label_metrics(label, y_targets, y_preds, threshold):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": metrics.accuracy_score(y_targets, y_preds),\n",
    "        \"precision\": metrics.precision_score(y_targets, y_preds, zero_division=0),\n",
    "        \"recall\": metrics.recall_score(y_targets, y_preds, zero_division=0),\n",
    "        \"f1\": metrics.f1_score(y_targets, y_preds, zero_division=0),\n",
    "        \"mcc\": metrics.matthews_corrcoef(y_targets, y_preds),\n",
    "        \"support\": y_targets.sum(),\n",
    "        \"threshold\": threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d2c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate overall metric on test set\n",
    "def calc_test_metrics(y_test, target_cols):\n",
    "    threshold = 0.6\n",
    "    # compute metrics\n",
    "    y_true = df_test[target_cols].values\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_micro = precision_score(y_true, y_pred, average='macro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='macro')\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'recall' : recall_micro,\n",
    "               'precision': precision_micro,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "\n",
    "    display(metrics_df)\n",
    "    \n",
    "    results = []\n",
    "    for label_index, label in enumerate(target_cols):\n",
    "        y_targets, y_preds = y_true[:, label_index], y_pred[:, label_index]\n",
    "        results.append(calc_label_metrics(label, y_targets, y_preds, threshold))\n",
    "\n",
    "    per_label_results = pd.DataFrame(results, index=target_cols)\n",
    "    display(per_label_results.drop(columns=[\"label\"]).round(3))\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the model and tokenizer in array\n",
    "models = [roberta_model, distilbert_model, roberta_model_2]\n",
    "tokenizers = [roberta_tokenizer, distilbert_tokenizer, roberta_tokenizer_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac823f56",
   "metadata": {},
   "source": [
    "## 3. Ensemble Fuzzy Integral Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab559e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genarate weight for models\n",
    "def generate_cardinality(N, p = 2):\n",
    "    return [(x/ N)**p for x in np.arange(N, 0, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8cd01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the prediction for each model and keep pred above the threshold value\n",
    "def fuzzy_integral_generalized(X, measure, axis = 0, f1 = np.minimum, f2 = np.amax, keepdims=True):\n",
    "    X_sorted = np.sort(X, axis = axis)\n",
    "    return f2(f1(np.take(X_sorted, np.arange(0, X_sorted.shape[axis]), axis), measure), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def predict(ensemble_prob):\n",
    "    predictions = np.zeros_like(ensemble_prob)\n",
    "    \n",
    "    for i in range(ensemble_prob.shape[0]):\n",
    "        temp = ensemble_prob[i]\n",
    "        # Thresholding: If value is greater than threshold, substitute with 1, else 0\n",
    "        predictions[i] = (temp >= 0.6).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7fee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load each model tokenizer, feed data into the model for prediction\n",
    "#Apply the fuzzy integral logic\n",
    "#Make predictions\n",
    "def my_ensemble(models, tokenizers, target_cols, df, y_true):\n",
    "    \n",
    "    count = 0\n",
    "    for model, tokenizer in zip(models, tokenizers):\n",
    "        count = count + 1\n",
    "        inputs = tokenizer(list(df['clean_text']), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(torch.Tensor(outputs.logits))\n",
    "        probs_np = probs.cpu().detach().numpy()\n",
    "        \n",
    "        if count == 1: \n",
    "            prob1 = probs_np\n",
    "        elif count == 2 :\n",
    "            prob2 = probs_np\n",
    "        else: \n",
    "            prob3 = probs_np\n",
    "        \n",
    "    num_classes = prob1.shape[1] #Get number of labels\n",
    "    Y = np.zeros(prob1.shape,dtype=float) #create a mask with 0s\n",
    "    \n",
    "    for samples in range(prob1.shape[0]): #loops the rows in the test set\n",
    "        for classes in range(prob1.shape[1]): #loop the classes\n",
    "            X = np.array([prob1[samples][classes], prob2[samples][classes],  prob3[samples][classes]])\n",
    "            measure = [0.5, 1.5, 1.8]\n",
    "            X_agg = fuzzy_integral_generalized(X,measure)\n",
    "            Y[samples][classes] = X_agg\n",
    "    \n",
    "    y_predictions = predict(Y)    \n",
    "    \n",
    "    correct = np.where(y_predictions == y_true)[0].shape[0]\n",
    "    total = y_true.shape[0]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predictions)\n",
    "    print(\"Accuracy = \",accuracy)\n",
    "\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de001dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.47392666298138936\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_ensemble(models, tokenizers, target_cols, df_test, df_test[target_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a20ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.601840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.563280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.646067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.774935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.473927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "f1         0.601840\n",
       "recall     0.563280\n",
       "precision  0.646067\n",
       "roc_auc    0.774935\n",
       "accuracy   0.473927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>support</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.669</td>\n",
       "      <td>504</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.822</td>\n",
       "      <td>264</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.493</td>\n",
       "      <td>198</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.291</td>\n",
       "      <td>320</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.390</td>\n",
       "      <td>351</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.401</td>\n",
       "      <td>135</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.455</td>\n",
       "      <td>153</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.375</td>\n",
       "      <td>284</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.542</td>\n",
       "      <td>83</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.310</td>\n",
       "      <td>151</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.373</td>\n",
       "      <td>267</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>123</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.512</td>\n",
       "      <td>37</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.400</td>\n",
       "      <td>103</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.704</td>\n",
       "      <td>78</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.917</td>\n",
       "      <td>352</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.572</td>\n",
       "      <td>161</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.796</td>\n",
       "      <td>238</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.314</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.572</td>\n",
       "      <td>186</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.288</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.283</td>\n",
       "      <td>145</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.678</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.570</td>\n",
       "      <td>156</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.512</td>\n",
       "      <td>141</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.519</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision  recall     f1    mcc  support  threshold\n",
       "admiration         0.939      0.646   0.762  0.699  0.669      504        0.6\n",
       "amusement          0.982      0.764   0.905  0.828  0.822      264        0.6\n",
       "anger              0.966      0.533   0.490  0.511  0.493      198        0.6\n",
       "annoyance          0.939      0.464   0.219  0.297  0.291      320        0.6\n",
       "approval           0.939      0.543   0.325  0.406  0.390      351        0.6\n",
       "caring             0.974      0.471   0.363  0.410  0.401      135        0.6\n",
       "confusion          0.973      0.525   0.418  0.465  0.455      153        0.6\n",
       "curiosity          0.943      0.443   0.370  0.403  0.375      284        0.6\n",
       "desire             0.988      0.655   0.458  0.539  0.542       83        0.6\n",
       "disappointment     0.974      0.591   0.172  0.267  0.310      151        0.6\n",
       "disapproval        0.945      0.428   0.378  0.402  0.373      267        0.6\n",
       "disgust            0.982      0.644   0.455  0.533  0.533      123        0.6\n",
       "embarrassment      0.995      0.700   0.378  0.491  0.512       37        0.6\n",
       "excitement         0.982      0.554   0.301  0.390  0.400      103        0.6\n",
       "fear               0.991      0.674   0.744  0.707  0.704       78        0.6\n",
       "gratitude          0.990      0.931   0.915  0.923  0.917      352        0.6\n",
       "grief              0.999      0.000   0.000  0.000  0.000        6        0.6\n",
       "joy                0.977      0.630   0.540  0.582  0.572      161        0.6\n",
       "love               0.981      0.743   0.874  0.803  0.796      238        0.6\n",
       "nervousness        0.996      0.571   0.174  0.267  0.314       23        0.6\n",
       "optimism           0.975      0.669   0.511  0.579  0.572      186        0.6\n",
       "pride              0.997      0.667   0.125  0.211  0.288       16        0.6\n",
       "realization        0.973      0.466   0.186  0.266  0.283      145        0.6\n",
       "relief             0.998      0.000   0.000  0.000  0.000       11        0.6\n",
       "remorse            0.992      0.606   0.768  0.677  0.678       56        0.6\n",
       "sadness            0.977      0.620   0.545  0.580  0.570      156        0.6\n",
       "surprise           0.975      0.525   0.525  0.525  0.512      141        0.6\n",
       "neutral            0.790      0.691   0.656  0.673  0.519     1787        0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets, predictions = calc_test_metrics(y_pred, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1631d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "         Actual                Predicted\n",
      "0     [sadness]          [love, remorse]\n",
      "1  [admiration]             [admiration]\n",
      "2  [excitement]               [optimism]\n",
      "3   [gratitude]              [gratitude]\n",
      "4     [neutral]                [neutral]\n",
      "5   [gratitude]              [gratitude]\n",
      "6   [gratitude]              [gratitude]\n",
      "7   [gratitude]  [admiration, gratitude]\n",
      "8     [remorse]                [remorse]\n",
      "9     [sadness]                [sadness]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store actual labels and predicted labels\n",
    "final_df = pd.DataFrame({\n",
    "    'Actual': [list(np.where(targets[i])[0]) for i in range(len(targets))],\n",
    "    'Predicted': [list(np.where(predictions[i])[0]) for i in range(len(predictions))]\n",
    "})\n",
    "\n",
    "# Map label indices to label names in the 'Actual' column\n",
    "final_df['Actual'] = final_df['Actual'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Map label indices to label names in the 'Predicted' column\n",
    "final_df['Predicted'] = final_df['Predicted'].apply(lambda indices: [target_cols[idx] for idx in indices])\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "301ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the label DataFrame with the original DataFramev\n",
    "val_df_terms = df_test['clean_text']\n",
    "result_df = pd.concat([val_df_terms, final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a335fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am really sorry about your situation frown s...</td>\n",
       "      <td>[sadness]</td>\n",
       "      <td>[love, remorse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is wonderful because it is awful at not with</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kings fan here good luck to you guys will be a...</td>\n",
       "      <td>[excitement]</td>\n",
       "      <td>[optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did not know that thank you for teaching me ...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they got bored from haunting earth for thousan...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>thanks i was diagnosed with bp 1 after the hos...</td>\n",
       "      <td>[gratitude]</td>\n",
       "      <td>[gratitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>well that makes sense</td>\n",
       "      <td>[approval]</td>\n",
       "      <td>[approval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>daddy issues name</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>so glad i discovered that subreddit a couple m...</td>\n",
       "      <td>[admiration]</td>\n",
       "      <td>[admiration, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>had to watch elmo in grouchland one time too m...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text        Actual  \\\n",
       "0     i am really sorry about your situation frown s...     [sadness]   \n",
       "1       it is wonderful because it is awful at not with  [admiration]   \n",
       "2     kings fan here good luck to you guys will be a...  [excitement]   \n",
       "3     i did not know that thank you for teaching me ...   [gratitude]   \n",
       "4     they got bored from haunting earth for thousan...     [neutral]   \n",
       "...                                                 ...           ...   \n",
       "5422  thanks i was diagnosed with bp 1 after the hos...   [gratitude]   \n",
       "5423                              well that makes sense    [approval]   \n",
       "5424                                  daddy issues name     [neutral]   \n",
       "5425  so glad i discovered that subreddit a couple m...  [admiration]   \n",
       "5426  had to watch elmo in grouchland one time too m...     [neutral]   \n",
       "\n",
       "              Predicted  \n",
       "0       [love, remorse]  \n",
       "1          [admiration]  \n",
       "2            [optimism]  \n",
       "3           [gratitude]  \n",
       "4             [neutral]  \n",
       "...                 ...  \n",
       "5422        [gratitude]  \n",
       "5423         [approval]  \n",
       "5424          [neutral]  \n",
       "5425  [admiration, joy]  \n",
       "5426          [neutral]  \n",
       "\n",
       "[5427 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5113b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to csv\n",
    "result_df.to_csv('output_ensemble_2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b778c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
